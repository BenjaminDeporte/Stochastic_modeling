{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "938bfb9b",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 40px; color: black; font-weight: bold;\">\n",
    "Pyro - Bayesian regression\n",
    "\n",
    "Here, we try to use a *deterministic* neural network, and a *stochastic* observation noise.\n",
    "\n",
    "This causes nasty bugs in the SVI logic (double pass in backward pass)\n",
    "\n",
    "Do NOT use this\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45d2ed0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.distributions.constraints as constraints\n",
    "from pyro.infer import MCMC, NUTS\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "import pyro.poutine as poutine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34c1c93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    \"\"\"\n",
    "    Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1473acc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "GPU Name: NVIDIA GeForce RTX 3080 Ti\n",
      "Total GPU Memory: 11.8 GB\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "# NB Warning : setting the default_device to CUDA creates a device conflict\n",
    "# when using a DataLoader, as it uses a CPU-generator for shuffling\n",
    "torch.set_default_device(device)\n",
    "\n",
    "print(f\"Using {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print('GPU Name:', torch.cuda.get_device_name(0))\n",
    "    print('Total GPU Memory:', round(torch.cuda.get_device_properties(0).total_memory/1024**3,1), 'GB')\n",
    "\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81f5c1f",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 30px; color: black; font-weight: bold;\">\n",
    "0 : Generate synthetic data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6a55acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_function(X:torch.Tensor) -> torch.Tensor:\n",
    "    y = X * torch.sin(6*torch.pi*X)\n",
    "    return y\n",
    "\n",
    "N_POINTS = 100\n",
    "\n",
    "noise = torch.tensor([0.1])\n",
    "X = torch.linspace(0.0, 1.0, steps=N_POINTS)\n",
    "y = target_function(X) + torch.randn(N_POINTS)*noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "689a8593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "ax.scatter(X.cpu(),y.cpu(),label='ground truth', marker='.')\n",
    "ax.grid()\n",
    "ax.set_title(f'Ground truth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b883a29c",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 30px; color: black; font-weight: bold;\">\n",
    "1 : Pyro model with a deterministic neural network : CAREFUL\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea441cb",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008B8B; padding: 15px; border-radius: 5px; font-size: 30px; color: black; font-weight: bold;\">\n",
    "Final Rule for Hybrid SVI Models after a lengthy and painful debugging\n",
    "</div>\n",
    "\n",
    "The practical rule learned from this extensive debugging session is:\n",
    "\n",
    "For deep, deterministic neural networks optimized via Pyro's SVI, avoid using the nn.Module.forward() method inside the model function. \n",
    "\n",
    "Instead, use the functional API (F.linear, F.relu, etc.) after manually retrieving the weights and biases from the parameter store using pyro.param().\n",
    "\n",
    "This guarantees that the PyTorch autograd system receives the simplest, cleanest computational graph possible, resolving the persistent RuntimeError."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f880492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deterministic part : neural network\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    The usual basic MLP class\n",
    "    \"\"\"\n",
    "    def __init__(self, n_layers=2, n_hidden_units=32, activation=nn.Tanh(), input_dim=1, output_dim=1, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden_units = n_hidden_units\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, n_hidden_units)\n",
    "        self.fc2 = nn.Linear(n_hidden_units, n_hidden_units)\n",
    "        self.fc3 = nn.Linear(n_hidden_units, output_dim)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # We don't use this, as this causes nasty conflicts with the SVI logic\n",
    "        # but keep it for completeness\n",
    "        x_ = x.unsqueeze(1) if x.dim() == 1 else x\n",
    "        x_ = self.activation(self.fc1(x_))\n",
    "        x_ = self.activation(self.fc2(x_))\n",
    "        x_ = self.fc3(x_)\n",
    "        \n",
    "        return x_.squeeze()\n",
    "    \n",
    "    def __repr__(self):\n",
    "        msg = f'object MLP - input dim = {self.input_dim}, output_dim = {self.output_dim}, num layers = {self.n_layers}, hidden units = {self.n_hidden_units}\\n'\n",
    "        msg += super().__repr__()\n",
    "        return msg\n",
    "    \n",
    "mlp = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8dd8eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple regression model\n",
    "# the learned function is deterministic (this is the MLP)\n",
    "# the observation noise is a random variable\n",
    "\n",
    "# we need to register manually the weights of the MLP\n",
    "# and run the forward pass manually...\n",
    "\n",
    "def model(X, y=None):\n",
    "    # # inputs: ----------------------\n",
    "    # #   X : torch.tensor(N,1)\n",
    "    # #   y : torch.tensor(N,1) if provided\n",
    "      \n",
    "    # priors ---------------------------------\n",
    "    # the only prior, for now, is the log standard deviation of the gaussian observation noise\n",
    "    log_noise_std = torch.exp(pyro.sample(\"log_noise_std\", dist.Normal(0.0, 0.1)))\n",
    "    \n",
    "    # parameters : retrieve all deterministic MLP parameters manually\n",
    "    params = {}\n",
    "    for name, _ in mlp.named_parameters():\n",
    "        params[name] = pyro.param(f\"det_{name}\")\n",
    "        \n",
    "    # 3. Manually run the forward pass\n",
    "    activation = nn.Tanh()\n",
    "    x_ = X.unsqueeze(1) if X.dim() == 1 else X\n",
    "    x_ = activation(F.linear(x_, params['fc1.weight'], params['fc1.bias']))\n",
    "    x_ = activation(F.linear(x_, params['fc2.weight'], params['fc2.bias']))\n",
    "    x_ = F.linear(x_, params['fc3.weight'], params['fc3.bias'])\n",
    "    means = x_.squeeze()\n",
    "    \n",
    "    # 4. Likelihood\n",
    "    noise_std = torch.exp(log_noise_std)\n",
    "    with pyro.plate(\"data\", len(X)):\n",
    "        pyro.sample(\"obs\", dist.Normal(means, noise_std), obs=y)\n",
    "    \n",
    "    return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "249b389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to learn the parameters, we implement a SVI without an approximate posterior\n",
    "def q_phi(X,y=None):\n",
    "    \"\"\"\n",
    "    the approximate posterior of the log noise standard deviation\n",
    "    \"\"\"\n",
    "    # learnable parameters for the log of the standard deviation of the observation noise\n",
    "    log_noise_std_loc = pyro.param(\"log_noise_std_loc\", torch.tensor(-2.0))\n",
    "    log_noise_std_std = pyro.param(\"log_noise_std_scale\", torch.tensor((0.1)), constraint=constraints.positive)\n",
    "    \n",
    "    # actual posterior for the log_noise_std\n",
    "    pyro.sample(\"log_noise_std\", dist.Normal(log_noise_std_loc, log_noise_std_std))    \n",
    "    \n",
    "    # Manually register all MLP parameters\n",
    "    for name, param in mlp.named_parameters():\n",
    "        pyro.param(f\"det_{name}\", param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcaa43c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer - using the Pyro wrapper for Adam\n",
    "optimizer = Adam(\n",
    "    {\"lr\": 1e-2}\n",
    ")\n",
    "\n",
    "# instantiate the SVI engine\n",
    "svi = SVI(\n",
    "    model=model,\n",
    "    guide=q_phi,\n",
    "    optim=optimizer,\n",
    "    loss=Trace_ELBO(retain_graph=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cf6cae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1      / 2000   - loss = 3.195e+02 - val loss = 3.356e+02 -- est. noise std mean : 0.137\n",
      "Epoch 2      / 2000   - loss = 3.152e+02 - val loss = 3.268e+02 -- est. noise std mean : 0.138\n",
      "Epoch 3      / 2000   - loss = 2.920e+02 - val loss = 2.804e+02 -- est. noise std mean : 0.139\n",
      "Epoch 4      / 2000   - loss = 3.268e+02 - val loss = 3.005e+02 -- est. noise std mean : 0.141\n",
      "Epoch 5      / 2000   - loss = 3.224e+02 - val loss = 2.967e+02 -- est. noise std mean : 0.142\n",
      "Epoch 6      / 2000   - loss = 3.070e+02 - val loss = 3.201e+02 -- est. noise std mean : 0.144\n",
      "Epoch 7      / 2000   - loss = 3.118e+02 - val loss = 3.011e+02 -- est. noise std mean : 0.145\n",
      "Epoch 8      / 2000   - loss = 2.684e+02 - val loss = 2.926e+02 -- est. noise std mean : 0.147\n",
      "Epoch 9      / 2000   - loss = 3.135e+02 - val loss = 2.946e+02 -- est. noise std mean : 0.148\n",
      "Epoch 10     / 2000   - loss = 2.965e+02 - val loss = 3.000e+02 -- est. noise std mean : 0.150\n",
      "Epoch 11     / 2000   - loss = 3.260e+02 - val loss = 3.056e+02 -- est. noise std mean : 0.151\n",
      "Epoch 12     / 2000   - loss = 2.928e+02 - val loss = 2.662e+02 -- est. noise std mean : 0.153\n",
      "Epoch 13     / 2000   - loss = 3.006e+02 - val loss = 2.851e+02 -- est. noise std mean : 0.154\n",
      "Epoch 14     / 2000   - loss = 2.783e+02 - val loss = 2.792e+02 -- est. noise std mean : 0.156\n",
      "Epoch 15     / 2000   - loss = 2.942e+02 - val loss = 2.722e+02 -- est. noise std mean : 0.157\n",
      "Epoch 16     / 2000   - loss = 2.866e+02 - val loss = 2.618e+02 -- est. noise std mean : 0.159\n",
      "Epoch 17     / 2000   - loss = 2.851e+02 - val loss = 2.745e+02 -- est. noise std mean : 0.160\n",
      "Epoch 18     / 2000   - loss = 3.042e+02 - val loss = 3.082e+02 -- est. noise std mean : 0.162\n",
      "Epoch 19     / 2000   - loss = 2.856e+02 - val loss = 3.066e+02 -- est. noise std mean : 0.163\n",
      "Epoch 20     / 2000   - loss = 3.050e+02 - val loss = 2.784e+02 -- est. noise std mean : 0.165\n",
      "Epoch 21     / 2000   - loss = 2.869e+02 - val loss = 2.673e+02 -- est. noise std mean : 0.167\n",
      "Epoch 22     / 2000   - loss = 2.876e+02 - val loss = 2.763e+02 -- est. noise std mean : 0.168\n",
      "Epoch 23     / 2000   - loss = 2.809e+02 - val loss = 2.926e+02 -- est. noise std mean : 0.170\n",
      "Epoch 24     / 2000   - loss = 2.936e+02 - val loss = 2.510e+02 -- est. noise std mean : 0.172\n",
      "Epoch 25     / 2000   - loss = 2.645e+02 - val loss = 2.660e+02 -- est. noise std mean : 0.173\n",
      "Epoch 26     / 2000   - loss = 2.890e+02 - val loss = 2.859e+02 -- est. noise std mean : 0.175\n",
      "Epoch 27     / 2000   - loss = 2.820e+02 - val loss = 2.532e+02 -- est. noise std mean : 0.177\n",
      "Epoch 28     / 2000   - loss = 2.388e+02 - val loss = 2.845e+02 -- est. noise std mean : 0.178\n",
      "Epoch 29     / 2000   - loss = 2.766e+02 - val loss = 2.678e+02 -- est. noise std mean : 0.180\n",
      "Epoch 30     / 2000   - loss = 2.516e+02 - val loss = 2.582e+02 -- est. noise std mean : 0.182\n",
      "Epoch 31     / 2000   - loss = 2.743e+02 - val loss = 2.474e+02 -- est. noise std mean : 0.184\n",
      "Epoch 32     / 2000   - loss = 2.453e+02 - val loss = 2.749e+02 -- est. noise std mean : 0.185\n",
      "Epoch 33     / 2000   - loss = 2.800e+02 - val loss = 2.749e+02 -- est. noise std mean : 0.187\n",
      "Epoch 34     / 2000   - loss = 2.596e+02 - val loss = 2.657e+02 -- est. noise std mean : 0.189\n",
      "Epoch 35     / 2000   - loss = 2.538e+02 - val loss = 2.482e+02 -- est. noise std mean : 0.191\n",
      "Epoch 36     / 2000   - loss = 2.442e+02 - val loss = 2.893e+02 -- est. noise std mean : 0.192\n",
      "Epoch 37     / 2000   - loss = 2.509e+02 - val loss = 2.754e+02 -- est. noise std mean : 0.194\n",
      "Epoch 38     / 2000   - loss = 2.626e+02 - val loss = 2.791e+02 -- est. noise std mean : 0.196\n",
      "Epoch 39     / 2000   - loss = 2.491e+02 - val loss = 2.481e+02 -- est. noise std mean : 0.198\n",
      "Epoch 40     / 2000   - loss = 2.407e+02 - val loss = 2.583e+02 -- est. noise std mean : 0.200\n",
      "Epoch 41     / 2000   - loss = 2.521e+02 - val loss = 2.418e+02 -- est. noise std mean : 0.201\n",
      "Epoch 42     / 2000   - loss = 2.304e+02 - val loss = 2.545e+02 -- est. noise std mean : 0.203\n",
      "Epoch 43     / 2000   - loss = 2.417e+02 - val loss = 2.518e+02 -- est. noise std mean : 0.205\n",
      "Epoch 44     / 2000   - loss = 2.313e+02 - val loss = 2.392e+02 -- est. noise std mean : 0.207\n",
      "Epoch 45     / 2000   - loss = 2.299e+02 - val loss = 2.488e+02 -- est. noise std mean : 0.209\n",
      "Epoch 46     / 2000   - loss = 2.340e+02 - val loss = 2.326e+02 -- est. noise std mean : 0.211\n",
      "Epoch 47     / 2000   - loss = 2.327e+02 - val loss = 2.374e+02 -- est. noise std mean : 0.212\n",
      "Epoch 48     / 2000   - loss = 2.500e+02 - val loss = 2.267e+02 -- est. noise std mean : 0.214\n",
      "Epoch 49     / 2000   - loss = 2.475e+02 - val loss = 2.291e+02 -- est. noise std mean : 0.216\n",
      "Epoch 50     / 2000   - loss = 2.451e+02 - val loss = 2.404e+02 -- est. noise std mean : 0.218\n",
      "Epoch 51     / 2000   - loss = 2.372e+02 - val loss = 2.014e+02 -- est. noise std mean : 0.220\n",
      "Epoch 52     / 2000   - loss = 2.381e+02 - val loss = 2.382e+02 -- est. noise std mean : 0.222\n",
      "Epoch 53     / 2000   - loss = 2.244e+02 - val loss = 2.409e+02 -- est. noise std mean : 0.224\n",
      "Epoch 54     / 2000   - loss = 2.360e+02 - val loss = 2.374e+02 -- est. noise std mean : 0.226\n",
      "Epoch 55     / 2000   - loss = 2.479e+02 - val loss = 2.339e+02 -- est. noise std mean : 0.228\n",
      "Epoch 56     / 2000   - loss = 2.337e+02 - val loss = 2.198e+02 -- est. noise std mean : 0.230\n",
      "Epoch 57     / 2000   - loss = 2.338e+02 - val loss = 2.239e+02 -- est. noise std mean : 0.232\n",
      "Epoch 58     / 2000   - loss = 2.374e+02 - val loss = 2.240e+02 -- est. noise std mean : 0.234\n",
      "Epoch 59     / 2000   - loss = 2.361e+02 - val loss = 2.222e+02 -- est. noise std mean : 0.236\n",
      "Epoch 60     / 2000   - loss = 2.319e+02 - val loss = 2.304e+02 -- est. noise std mean : 0.238\n",
      "Epoch 61     / 2000   - loss = 2.434e+02 - val loss = 2.293e+02 -- est. noise std mean : 0.240\n",
      "Epoch 62     / 2000   - loss = 2.238e+02 - val loss = 2.069e+02 -- est. noise std mean : 0.242\n",
      "Epoch 63     / 2000   - loss = 2.076e+02 - val loss = 2.123e+02 -- est. noise std mean : 0.244\n",
      "Epoch 64     / 2000   - loss = 2.223e+02 - val loss = 2.231e+02 -- est. noise std mean : 0.246\n",
      "Epoch 65     / 2000   - loss = 2.365e+02 - val loss = 2.160e+02 -- est. noise std mean : 0.248\n",
      "Epoch 66     / 2000   - loss = 2.158e+02 - val loss = 2.106e+02 -- est. noise std mean : 0.250\n",
      "Epoch 67     / 2000   - loss = 2.158e+02 - val loss = 2.334e+02 -- est. noise std mean : 0.252\n",
      "Epoch 68     / 2000   - loss = 1.951e+02 - val loss = 2.240e+02 -- est. noise std mean : 0.254\n",
      "Epoch 69     / 2000   - loss = 2.027e+02 - val loss = 2.247e+02 -- est. noise std mean : 0.256\n",
      "Epoch 70     / 2000   - loss = 2.112e+02 - val loss = 2.084e+02 -- est. noise std mean : 0.258\n",
      "Epoch 71     / 2000   - loss = 2.108e+02 - val loss = 2.029e+02 -- est. noise std mean : 0.260\n",
      "Epoch 72     / 2000   - loss = 1.998e+02 - val loss = 2.200e+02 -- est. noise std mean : 0.262\n",
      "Epoch 73     / 2000   - loss = 2.325e+02 - val loss = 2.143e+02 -- est. noise std mean : 0.264\n",
      "Epoch 74     / 2000   - loss = 2.064e+02 - val loss = 2.276e+02 -- est. noise std mean : 0.266\n",
      "Epoch 75     / 2000   - loss = 2.143e+02 - val loss = 2.112e+02 -- est. noise std mean : 0.269\n",
      "Epoch 76     / 2000   - loss = 2.090e+02 - val loss = 2.029e+02 -- est. noise std mean : 0.271\n",
      "Epoch 77     / 2000   - loss = 2.215e+02 - val loss = 1.897e+02 -- est. noise std mean : 0.273\n",
      "Epoch 78     / 2000   - loss = 2.086e+02 - val loss = 2.085e+02 -- est. noise std mean : 0.275\n",
      "Epoch 79     / 2000   - loss = 2.077e+02 - val loss = 2.125e+02 -- est. noise std mean : 0.277\n",
      "Epoch 80     / 2000   - loss = 2.005e+02 - val loss = 2.080e+02 -- est. noise std mean : 0.279\n",
      "Epoch 81     / 2000   - loss = 2.060e+02 - val loss = 2.212e+02 -- est. noise std mean : 0.281\n",
      "Epoch 82     / 2000   - loss = 1.981e+02 - val loss = 2.088e+02 -- est. noise std mean : 0.283\n",
      "Epoch 83     / 2000   - loss = 2.020e+02 - val loss = 2.070e+02 -- est. noise std mean : 0.285\n",
      "Epoch 84     / 2000   - loss = 1.938e+02 - val loss = 1.973e+02 -- est. noise std mean : 0.287\n",
      "Epoch 85     / 2000   - loss = 2.015e+02 - val loss = 1.999e+02 -- est. noise std mean : 0.289\n",
      "Epoch 86     / 2000   - loss = 2.027e+02 - val loss = 2.040e+02 -- est. noise std mean : 0.292\n",
      "Epoch 87     / 2000   - loss = 2.046e+02 - val loss = 2.157e+02 -- est. noise std mean : 0.294\n",
      "Epoch 88     / 2000   - loss = 1.974e+02 - val loss = 2.080e+02 -- est. noise std mean : 0.296\n",
      "Epoch 89     / 2000   - loss = 2.015e+02 - val loss = 2.052e+02 -- est. noise std mean : 0.298\n",
      "Epoch 90     / 2000   - loss = 2.056e+02 - val loss = 1.840e+02 -- est. noise std mean : 0.300\n",
      "Epoch 91     / 2000   - loss = 1.938e+02 - val loss = 1.843e+02 -- est. noise std mean : 0.302\n",
      "Epoch 92     / 2000   - loss = 1.777e+02 - val loss = 1.948e+02 -- est. noise std mean : 0.304\n",
      "Epoch 93     / 2000   - loss = 1.943e+02 - val loss = 1.931e+02 -- est. noise std mean : 0.306\n",
      "Epoch 94     / 2000   - loss = 2.020e+02 - val loss = 2.027e+02 -- est. noise std mean : 0.308\n",
      "Epoch 95     / 2000   - loss = 2.040e+02 - val loss = 1.950e+02 -- est. noise std mean : 0.310\n",
      "Epoch 96     / 2000   - loss = 1.942e+02 - val loss = 1.944e+02 -- est. noise std mean : 0.313\n",
      "Epoch 97     / 2000   - loss = 1.913e+02 - val loss = 1.976e+02 -- est. noise std mean : 0.315\n",
      "Epoch 98     / 2000   - loss = 1.978e+02 - val loss = 1.921e+02 -- est. noise std mean : 0.317\n",
      "Epoch 99     / 2000   - loss = 1.887e+02 - val loss = 2.003e+02 -- est. noise std mean : 0.319\n",
      "Epoch 100    / 2000   - loss = 2.005e+02 - val loss = 1.948e+02 -- est. noise std mean : 0.321\n",
      "Epoch 101    / 2000   - loss = 1.928e+02 - val loss = 1.935e+02 -- est. noise std mean : 0.323\n",
      "Epoch 102    / 2000   - loss = 1.820e+02 - val loss = 1.838e+02 -- est. noise std mean : 0.325\n",
      "Epoch 103    / 2000   - loss = 1.903e+02 - val loss = 1.802e+02 -- est. noise std mean : 0.327\n",
      "Epoch 104    / 2000   - loss = 1.839e+02 - val loss = 1.923e+02 -- est. noise std mean : 0.329\n",
      "Epoch 105    / 2000   - loss = 2.063e+02 - val loss = 1.914e+02 -- est. noise std mean : 0.332\n",
      "Epoch 106    / 2000   - loss = 1.871e+02 - val loss = 1.873e+02 -- est. noise std mean : 0.334\n",
      "Epoch 107    / 2000   - loss = 1.986e+02 - val loss = 2.001e+02 -- est. noise std mean : 0.336\n",
      "Epoch 108    / 2000   - loss = 1.928e+02 - val loss = 1.867e+02 -- est. noise std mean : 0.338\n",
      "Epoch 109    / 2000   - loss = 1.987e+02 - val loss = 1.738e+02 -- est. noise std mean : 0.340\n",
      "Epoch 110    / 2000   - loss = 1.823e+02 - val loss = 1.751e+02 -- est. noise std mean : 0.342\n",
      "Epoch 111    / 2000   - loss = 1.939e+02 - val loss = 1.841e+02 -- est. noise std mean : 0.345\n",
      "Epoch 112    / 2000   - loss = 1.936e+02 - val loss = 1.945e+02 -- est. noise std mean : 0.347\n",
      "Epoch 113    / 2000   - loss = 1.952e+02 - val loss = 1.915e+02 -- est. noise std mean : 0.349\n",
      "Epoch 114    / 2000   - loss = 1.911e+02 - val loss = 1.890e+02 -- est. noise std mean : 0.351\n",
      "Epoch 115    / 2000   - loss = 1.873e+02 - val loss = 1.902e+02 -- est. noise std mean : 0.354\n",
      "Epoch 116    / 2000   - loss = 1.920e+02 - val loss = 1.814e+02 -- est. noise std mean : 0.356\n",
      "Epoch 117    / 2000   - loss = 1.969e+02 - val loss = 1.751e+02 -- est. noise std mean : 0.358\n",
      "Epoch 118    / 2000   - loss = 1.860e+02 - val loss = 1.762e+02 -- est. noise std mean : 0.360\n",
      "Epoch 119    / 2000   - loss = 1.791e+02 - val loss = 1.813e+02 -- est. noise std mean : 0.363\n",
      "Epoch 120    / 2000   - loss = 1.817e+02 - val loss = 1.803e+02 -- est. noise std mean : 0.365\n",
      "Epoch 121    / 2000   - loss = 1.857e+02 - val loss = 1.686e+02 -- est. noise std mean : 0.367\n",
      "Epoch 122    / 2000   - loss = 1.744e+02 - val loss = 1.814e+02 -- est. noise std mean : 0.369\n",
      "Epoch 123    / 2000   - loss = 1.869e+02 - val loss = 1.798e+02 -- est. noise std mean : 0.372\n",
      "Epoch 124    / 2000   - loss = 1.797e+02 - val loss = 1.734e+02 -- est. noise std mean : 0.374\n",
      "Epoch 125    / 2000   - loss = 1.784e+02 - val loss = 1.838e+02 -- est. noise std mean : 0.376\n",
      "Epoch 126    / 2000   - loss = 1.846e+02 - val loss = 1.767e+02 -- est. noise std mean : 0.378\n",
      "Epoch 127    / 2000   - loss = 1.813e+02 - val loss = 1.778e+02 -- est. noise std mean : 0.380\n",
      "Epoch 128    / 2000   - loss = 1.812e+02 - val loss = 1.806e+02 -- est. noise std mean : 0.382\n",
      "Epoch 129    / 2000   - loss = 1.737e+02 - val loss = 1.800e+02 -- est. noise std mean : 0.384\n",
      "Epoch 130    / 2000   - loss = 1.859e+02 - val loss = 1.764e+02 -- est. noise std mean : 0.386\n",
      "Epoch 131    / 2000   - loss = 1.857e+02 - val loss = 1.832e+02 -- est. noise std mean : 0.389\n",
      "Epoch 132    / 2000   - loss = 1.782e+02 - val loss = 1.822e+02 -- est. noise std mean : 0.391\n",
      "Epoch 133    / 2000   - loss = 1.791e+02 - val loss = 1.718e+02 -- est. noise std mean : 0.393\n",
      "Epoch 134    / 2000   - loss = 1.785e+02 - val loss = 1.731e+02 -- est. noise std mean : 0.395\n",
      "Epoch 135    / 2000   - loss = 1.752e+02 - val loss = 1.741e+02 -- est. noise std mean : 0.397\n",
      "Epoch 136    / 2000   - loss = 1.816e+02 - val loss = 1.822e+02 -- est. noise std mean : 0.399\n",
      "Epoch 137    / 2000   - loss = 1.802e+02 - val loss = 1.805e+02 -- est. noise std mean : 0.401\n",
      "Epoch 138    / 2000   - loss = 1.753e+02 - val loss = 1.808e+02 -- est. noise std mean : 0.403\n",
      "Epoch 139    / 2000   - loss = 1.746e+02 - val loss = 1.759e+02 -- est. noise std mean : 0.405\n",
      "Epoch 140    / 2000   - loss = 1.795e+02 - val loss = 1.791e+02 -- est. noise std mean : 0.407\n",
      "Epoch 141    / 2000   - loss = 1.765e+02 - val loss = 1.770e+02 -- est. noise std mean : 0.409\n",
      "Epoch 142    / 2000   - loss = 1.780e+02 - val loss = 1.730e+02 -- est. noise std mean : 0.411\n",
      "Epoch 143    / 2000   - loss = 1.768e+02 - val loss = 1.833e+02 -- est. noise std mean : 0.413\n",
      "Epoch 144    / 2000   - loss = 1.747e+02 - val loss = 1.735e+02 -- est. noise std mean : 0.415\n",
      "Epoch 145    / 2000   - loss = 1.691e+02 - val loss = 1.779e+02 -- est. noise std mean : 0.417\n",
      "Epoch 146    / 2000   - loss = 1.753e+02 - val loss = 1.773e+02 -- est. noise std mean : 0.419\n",
      "Epoch 147    / 2000   - loss = 1.721e+02 - val loss = 1.788e+02 -- est. noise std mean : 0.421\n",
      "Epoch 148    / 2000   - loss = 1.800e+02 - val loss = 1.796e+02 -- est. noise std mean : 0.423\n",
      "Epoch 149    / 2000   - loss = 1.857e+02 - val loss = 1.806e+02 -- est. noise std mean : 0.425\n",
      "Epoch 150    / 2000   - loss = 1.731e+02 - val loss = 1.685e+02 -- est. noise std mean : 0.427\n",
      "Epoch 151    / 2000   - loss = 1.764e+02 - val loss = 1.811e+02 -- est. noise std mean : 0.429\n",
      "Epoch 152    / 2000   - loss = 1.777e+02 - val loss = 1.738e+02 -- est. noise std mean : 0.431\n",
      "Epoch 153    / 2000   - loss = 1.687e+02 - val loss = 1.796e+02 -- est. noise std mean : 0.433\n",
      "Epoch 154    / 2000   - loss = 1.788e+02 - val loss = 1.759e+02 -- est. noise std mean : 0.435\n",
      "Epoch 155    / 2000   - loss = 1.678e+02 - val loss = 1.800e+02 -- est. noise std mean : 0.436\n",
      "Epoch 156    / 2000   - loss = 1.761e+02 - val loss = 1.747e+02 -- est. noise std mean : 0.438\n",
      "Epoch 157    / 2000   - loss = 1.725e+02 - val loss = 1.757e+02 -- est. noise std mean : 0.440\n",
      "Epoch 158    / 2000   - loss = 1.748e+02 - val loss = 1.717e+02 -- est. noise std mean : 0.442\n",
      "Epoch 159    / 2000   - loss = 1.708e+02 - val loss = 1.769e+02 -- est. noise std mean : 0.444\n",
      "Epoch 160    / 2000   - loss = 1.738e+02 - val loss = 1.738e+02 -- est. noise std mean : 0.446\n",
      "Epoch 161    / 2000   - loss = 1.766e+02 - val loss = 1.683e+02 -- est. noise std mean : 0.448\n",
      "Epoch 162    / 2000   - loss = 1.782e+02 - val loss = 1.659e+02 -- est. noise std mean : 0.449\n",
      "Epoch 163    / 2000   - loss = 1.741e+02 - val loss = 1.679e+02 -- est. noise std mean : 0.451\n",
      "Epoch 164    / 2000   - loss = 1.778e+02 - val loss = 1.751e+02 -- est. noise std mean : 0.453\n",
      "Epoch 165    / 2000   - loss = 1.755e+02 - val loss = 1.695e+02 -- est. noise std mean : 0.455\n",
      "Epoch 166    / 2000   - loss = 1.706e+02 - val loss = 1.708e+02 -- est. noise std mean : 0.457\n",
      "Epoch 167    / 2000   - loss = 1.659e+02 - val loss = 1.712e+02 -- est. noise std mean : 0.459\n",
      "Epoch 168    / 2000   - loss = 1.724e+02 - val loss = 1.700e+02 -- est. noise std mean : 0.461\n",
      "Epoch 169    / 2000   - loss = 1.704e+02 - val loss = 1.694e+02 -- est. noise std mean : 0.463\n",
      "Epoch 170    / 2000   - loss = 1.752e+02 - val loss = 1.659e+02 -- est. noise std mean : 0.465\n",
      "Epoch 171    / 2000   - loss = 1.715e+02 - val loss = 1.719e+02 -- est. noise std mean : 0.467\n",
      "Epoch 172    / 2000   - loss = 1.662e+02 - val loss = 1.699e+02 -- est. noise std mean : 0.468\n",
      "Epoch 173    / 2000   - loss = 1.690e+02 - val loss = 1.701e+02 -- est. noise std mean : 0.470\n",
      "Epoch 174    / 2000   - loss = 1.712e+02 - val loss = 1.709e+02 -- est. noise std mean : 0.472\n",
      "Epoch 175    / 2000   - loss = 1.712e+02 - val loss = 1.697e+02 -- est. noise std mean : 0.473\n",
      "Epoch 176    / 2000   - loss = 1.697e+02 - val loss = 1.728e+02 -- est. noise std mean : 0.475\n",
      "Epoch 177    / 2000   - loss = 1.687e+02 - val loss = 1.714e+02 -- est. noise std mean : 0.476\n",
      "Epoch 178    / 2000   - loss = 1.713e+02 - val loss = 1.706e+02 -- est. noise std mean : 0.478\n",
      "Epoch 179    / 2000   - loss = 1.682e+02 - val loss = 1.690e+02 -- est. noise std mean : 0.480\n",
      "Epoch 180    / 2000   - loss = 1.681e+02 - val loss = 1.664e+02 -- est. noise std mean : 0.481\n",
      "Epoch 181    / 2000   - loss = 1.681e+02 - val loss = 1.675e+02 -- est. noise std mean : 0.482\n",
      "Epoch 182    / 2000   - loss = 1.673e+02 - val loss = 1.688e+02 -- est. noise std mean : 0.484\n",
      "Epoch 183    / 2000   - loss = 1.721e+02 - val loss = 1.717e+02 -- est. noise std mean : 0.485\n",
      "Epoch 184    / 2000   - loss = 1.691e+02 - val loss = 1.672e+02 -- est. noise std mean : 0.487\n",
      "Epoch 185    / 2000   - loss = 1.696e+02 - val loss = 1.696e+02 -- est. noise std mean : 0.488\n",
      "Epoch 186    / 2000   - loss = 1.706e+02 - val loss = 1.666e+02 -- est. noise std mean : 0.489\n",
      "Epoch 187    / 2000   - loss = 1.688e+02 - val loss = 1.690e+02 -- est. noise std mean : 0.491\n",
      "Epoch 188    / 2000   - loss = 1.713e+02 - val loss = 1.702e+02 -- est. noise std mean : 0.492\n",
      "Epoch 189    / 2000   - loss = 1.675e+02 - val loss = 1.718e+02 -- est. noise std mean : 0.494\n",
      "Epoch 190    / 2000   - loss = 1.676e+02 - val loss = 1.684e+02 -- est. noise std mean : 0.495\n",
      "Epoch 191    / 2000   - loss = 1.637e+02 - val loss = 1.681e+02 -- est. noise std mean : 0.496\n",
      "Epoch 192    / 2000   - loss = 1.699e+02 - val loss = 1.688e+02 -- est. noise std mean : 0.498\n",
      "Epoch 193    / 2000   - loss = 1.653e+02 - val loss = 1.685e+02 -- est. noise std mean : 0.499\n",
      "Epoch 194    / 2000   - loss = 1.687e+02 - val loss = 1.693e+02 -- est. noise std mean : 0.500\n",
      "Epoch 195    / 2000   - loss = 1.658e+02 - val loss = 1.685e+02 -- est. noise std mean : 0.501\n",
      "Epoch 196    / 2000   - loss = 1.696e+02 - val loss = 1.707e+02 -- est. noise std mean : 0.502\n",
      "Epoch 197    / 2000   - loss = 1.649e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.503\n",
      "Epoch 198    / 2000   - loss = 1.680e+02 - val loss = 1.692e+02 -- est. noise std mean : 0.504\n",
      "Epoch 199    / 2000   - loss = 1.710e+02 - val loss = 1.659e+02 -- est. noise std mean : 0.505\n",
      "Epoch 200    / 2000   - loss = 1.676e+02 - val loss = 1.685e+02 -- est. noise std mean : 0.506\n",
      "Epoch 201    / 2000   - loss = 1.682e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.507\n",
      "Epoch 202    / 2000   - loss = 1.674e+02 - val loss = 1.660e+02 -- est. noise std mean : 0.508\n",
      "Epoch 203    / 2000   - loss = 1.686e+02 - val loss = 1.659e+02 -- est. noise std mean : 0.509\n",
      "Epoch 204    / 2000   - loss = 1.707e+02 - val loss = 1.645e+02 -- est. noise std mean : 0.510\n",
      "Epoch 205    / 2000   - loss = 1.679e+02 - val loss = 1.690e+02 -- est. noise std mean : 0.512\n",
      "Epoch 206    / 2000   - loss = 1.686e+02 - val loss = 1.676e+02 -- est. noise std mean : 0.513\n",
      "Epoch 207    / 2000   - loss = 1.694e+02 - val loss = 1.667e+02 -- est. noise std mean : 0.514\n",
      "Epoch 208    / 2000   - loss = 1.654e+02 - val loss = 1.676e+02 -- est. noise std mean : 0.515\n",
      "Epoch 209    / 2000   - loss = 1.686e+02 - val loss = 1.668e+02 -- est. noise std mean : 0.516\n",
      "Epoch 210    / 2000   - loss = 1.680e+02 - val loss = 1.671e+02 -- est. noise std mean : 0.518\n",
      "Epoch 211    / 2000   - loss = 1.660e+02 - val loss = 1.661e+02 -- est. noise std mean : 0.519\n",
      "Epoch 212    / 2000   - loss = 1.667e+02 - val loss = 1.681e+02 -- est. noise std mean : 0.520\n",
      "Epoch 213    / 2000   - loss = 1.686e+02 - val loss = 1.675e+02 -- est. noise std mean : 0.521\n",
      "Epoch 214    / 2000   - loss = 1.663e+02 - val loss = 1.681e+02 -- est. noise std mean : 0.522\n",
      "Epoch 215    / 2000   - loss = 1.679e+02 - val loss = 1.657e+02 -- est. noise std mean : 0.523\n",
      "Epoch 216    / 2000   - loss = 1.661e+02 - val loss = 1.660e+02 -- est. noise std mean : 0.524\n",
      "Epoch 217    / 2000   - loss = 1.680e+02 - val loss = 1.671e+02 -- est. noise std mean : 0.525\n",
      "Epoch 218    / 2000   - loss = 1.682e+02 - val loss = 1.669e+02 -- est. noise std mean : 0.526\n",
      "Epoch 219    / 2000   - loss = 1.675e+02 - val loss = 1.681e+02 -- est. noise std mean : 0.527\n",
      "Epoch 220    / 2000   - loss = 1.675e+02 - val loss = 1.686e+02 -- est. noise std mean : 0.528\n",
      "Epoch 221    / 2000   - loss = 1.660e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.529\n",
      "Epoch 222    / 2000   - loss = 1.670e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.530\n",
      "Epoch 223    / 2000   - loss = 1.658e+02 - val loss = 1.672e+02 -- est. noise std mean : 0.531\n",
      "Epoch 224    / 2000   - loss = 1.676e+02 - val loss = 1.661e+02 -- est. noise std mean : 0.532\n",
      "Epoch 225    / 2000   - loss = 1.658e+02 - val loss = 1.672e+02 -- est. noise std mean : 0.533\n",
      "Epoch 226    / 2000   - loss = 1.667e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.533\n",
      "Epoch 227    / 2000   - loss = 1.660e+02 - val loss = 1.668e+02 -- est. noise std mean : 0.534\n",
      "Epoch 228    / 2000   - loss = 1.677e+02 - val loss = 1.663e+02 -- est. noise std mean : 0.535\n",
      "Epoch 229    / 2000   - loss = 1.675e+02 - val loss = 1.672e+02 -- est. noise std mean : 0.536\n",
      "Epoch 230    / 2000   - loss = 1.673e+02 - val loss = 1.673e+02 -- est. noise std mean : 0.537\n",
      "Epoch 231    / 2000   - loss = 1.655e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.538\n",
      "Epoch 232    / 2000   - loss = 1.671e+02 - val loss = 1.647e+02 -- est. noise std mean : 0.538\n",
      "Epoch 233    / 2000   - loss = 1.670e+02 - val loss = 1.660e+02 -- est. noise std mean : 0.539\n",
      "Epoch 234    / 2000   - loss = 1.663e+02 - val loss = 1.659e+02 -- est. noise std mean : 0.540\n",
      "Epoch 235    / 2000   - loss = 1.656e+02 - val loss = 1.669e+02 -- est. noise std mean : 0.541\n",
      "Epoch 236    / 2000   - loss = 1.665e+02 - val loss = 1.674e+02 -- est. noise std mean : 0.542\n",
      "Epoch 237    / 2000   - loss = 1.662e+02 - val loss = 1.659e+02 -- est. noise std mean : 0.542\n",
      "Epoch 238    / 2000   - loss = 1.657e+02 - val loss = 1.665e+02 -- est. noise std mean : 0.543\n",
      "Epoch 239    / 2000   - loss = 1.654e+02 - val loss = 1.662e+02 -- est. noise std mean : 0.543\n",
      "Epoch 240    / 2000   - loss = 1.669e+02 - val loss = 1.660e+02 -- est. noise std mean : 0.544\n",
      "Epoch 241    / 2000   - loss = 1.664e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.544\n",
      "Epoch 242    / 2000   - loss = 1.663e+02 - val loss = 1.666e+02 -- est. noise std mean : 0.545\n",
      "Epoch 243    / 2000   - loss = 1.664e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.546\n",
      "Epoch 244    / 2000   - loss = 1.668e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.546\n",
      "Epoch 245    / 2000   - loss = 1.661e+02 - val loss = 1.667e+02 -- est. noise std mean : 0.547\n",
      "Epoch 246    / 2000   - loss = 1.669e+02 - val loss = 1.664e+02 -- est. noise std mean : 0.547\n",
      "Epoch 247    / 2000   - loss = 1.661e+02 - val loss = 1.663e+02 -- est. noise std mean : 0.548\n",
      "Epoch 248    / 2000   - loss = 1.660e+02 - val loss = 1.662e+02 -- est. noise std mean : 0.549\n",
      "Epoch 249    / 2000   - loss = 1.664e+02 - val loss = 1.665e+02 -- est. noise std mean : 0.549\n",
      "Epoch 250    / 2000   - loss = 1.661e+02 - val loss = 1.660e+02 -- est. noise std mean : 0.550\n",
      "Epoch 251    / 2000   - loss = 1.659e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.550\n",
      "Epoch 252    / 2000   - loss = 1.668e+02 - val loss = 1.663e+02 -- est. noise std mean : 0.551\n",
      "Epoch 253    / 2000   - loss = 1.663e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.552\n",
      "Epoch 254    / 2000   - loss = 1.656e+02 - val loss = 1.660e+02 -- est. noise std mean : 0.552\n",
      "Epoch 255    / 2000   - loss = 1.659e+02 - val loss = 1.659e+02 -- est. noise std mean : 0.553\n",
      "Epoch 256    / 2000   - loss = 1.660e+02 - val loss = 1.660e+02 -- est. noise std mean : 0.553\n",
      "Epoch 257    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.553\n",
      "Epoch 258    / 2000   - loss = 1.658e+02 - val loss = 1.664e+02 -- est. noise std mean : 0.554\n",
      "Epoch 259    / 2000   - loss = 1.660e+02 - val loss = 1.666e+02 -- est. noise std mean : 0.554\n",
      "Epoch 260    / 2000   - loss = 1.663e+02 - val loss = 1.663e+02 -- est. noise std mean : 0.555\n",
      "Epoch 261    / 2000   - loss = 1.658e+02 - val loss = 1.659e+02 -- est. noise std mean : 0.555\n",
      "Epoch 262    / 2000   - loss = 1.663e+02 - val loss = 1.657e+02 -- est. noise std mean : 0.555\n",
      "Epoch 263    / 2000   - loss = 1.662e+02 - val loss = 1.659e+02 -- est. noise std mean : 0.556\n",
      "Epoch 264    / 2000   - loss = 1.666e+02 - val loss = 1.659e+02 -- est. noise std mean : 0.556\n",
      "Epoch 265    / 2000   - loss = 1.663e+02 - val loss = 1.661e+02 -- est. noise std mean : 0.557\n",
      "Epoch 266    / 2000   - loss = 1.663e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.558\n",
      "Epoch 267    / 2000   - loss = 1.660e+02 - val loss = 1.659e+02 -- est. noise std mean : 0.558\n",
      "Epoch 268    / 2000   - loss = 1.659e+02 - val loss = 1.661e+02 -- est. noise std mean : 0.559\n",
      "Epoch 269    / 2000   - loss = 1.661e+02 - val loss = 1.660e+02 -- est. noise std mean : 0.560\n",
      "Epoch 270    / 2000   - loss = 1.659e+02 - val loss = 1.662e+02 -- est. noise std mean : 0.560\n",
      "Epoch 271    / 2000   - loss = 1.662e+02 - val loss = 1.661e+02 -- est. noise std mean : 0.561\n",
      "Epoch 272    / 2000   - loss = 1.660e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.561\n",
      "Epoch 273    / 2000   - loss = 1.659e+02 - val loss = 1.660e+02 -- est. noise std mean : 0.562\n",
      "Epoch 274    / 2000   - loss = 1.661e+02 - val loss = 1.659e+02 -- est. noise std mean : 0.563\n",
      "Epoch 275    / 2000   - loss = 1.660e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.563\n",
      "Epoch 276    / 2000   - loss = 1.658e+02 - val loss = 1.657e+02 -- est. noise std mean : 0.564\n",
      "Epoch 277    / 2000   - loss = 1.657e+02 - val loss = 1.660e+02 -- est. noise std mean : 0.564\n",
      "Epoch 278    / 2000   - loss = 1.661e+02 - val loss = 1.657e+02 -- est. noise std mean : 0.565\n",
      "Epoch 279    / 2000   - loss = 1.660e+02 - val loss = 1.657e+02 -- est. noise std mean : 0.565\n",
      "Epoch 280    / 2000   - loss = 1.657e+02 - val loss = 1.657e+02 -- est. noise std mean : 0.566\n",
      "Epoch 281    / 2000   - loss = 1.658e+02 - val loss = 1.659e+02 -- est. noise std mean : 0.566\n",
      "Epoch 282    / 2000   - loss = 1.659e+02 - val loss = 1.657e+02 -- est. noise std mean : 0.566\n",
      "Epoch 283    / 2000   - loss = 1.660e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.567\n",
      "Epoch 284    / 2000   - loss = 1.659e+02 - val loss = 1.659e+02 -- est. noise std mean : 0.567\n",
      "Epoch 285    / 2000   - loss = 1.658e+02 - val loss = 1.659e+02 -- est. noise std mean : 0.568\n",
      "Epoch 286    / 2000   - loss = 1.658e+02 - val loss = 1.659e+02 -- est. noise std mean : 0.568\n",
      "Epoch 287    / 2000   - loss = 1.659e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.568\n",
      "Epoch 288    / 2000   - loss = 1.659e+02 - val loss = 1.659e+02 -- est. noise std mean : 0.569\n",
      "Epoch 289    / 2000   - loss = 1.658e+02 - val loss = 1.659e+02 -- est. noise std mean : 0.569\n",
      "Epoch 290    / 2000   - loss = 1.658e+02 - val loss = 1.659e+02 -- est. noise std mean : 0.569\n",
      "Epoch 291    / 2000   - loss = 1.659e+02 - val loss = 1.659e+02 -- est. noise std mean : 0.569\n",
      "Epoch 292    / 2000   - loss = 1.658e+02 - val loss = 1.657e+02 -- est. noise std mean : 0.569\n",
      "Epoch 293    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.569\n",
      "Epoch 294    / 2000   - loss = 1.658e+02 - val loss = 1.659e+02 -- est. noise std mean : 0.569\n",
      "Epoch 295    / 2000   - loss = 1.659e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.569\n",
      "Epoch 296    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.570\n",
      "Epoch 297    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.570\n",
      "Epoch 298    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.570\n",
      "Epoch 299    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.570\n",
      "Epoch 300    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.570\n",
      "Epoch 301    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.570\n",
      "Epoch 302    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.570\n",
      "Epoch 303    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.570\n",
      "Epoch 304    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.570\n",
      "Epoch 305    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.570\n",
      "Epoch 306    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.570\n",
      "Epoch 307    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.570\n",
      "Epoch 308    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.570\n",
      "Epoch 309    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.570\n",
      "Epoch 310    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.570\n",
      "Epoch 311    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.570\n",
      "Epoch 312    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.570\n",
      "Epoch 313    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.570\n",
      "Epoch 314    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.570\n",
      "Epoch 315    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.570\n",
      "Epoch 316    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.570\n",
      "Epoch 317    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.570\n",
      "Epoch 318    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.570\n",
      "Epoch 319    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.571\n",
      "Epoch 320    / 2000   - loss = 1.658e+02 - val loss = 1.657e+02 -- est. noise std mean : 0.571\n",
      "Epoch 321    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.571\n",
      "Epoch 322    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.571\n",
      "Epoch 323    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.571\n",
      "Epoch 324    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.571\n",
      "Epoch 325    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.570\n",
      "Epoch 326    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.570\n",
      "Epoch 327    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.570\n",
      "Epoch 328    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.570\n",
      "Epoch 329    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.570\n",
      "Epoch 330    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.570\n",
      "Epoch 331    / 2000   - loss = 1.658e+02 - val loss = 1.657e+02 -- est. noise std mean : 0.570\n",
      "Epoch 332    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.570\n",
      "Epoch 333    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.570\n",
      "Epoch 334    / 2000   - loss = 1.658e+02 - val loss = 1.657e+02 -- est. noise std mean : 0.569\n",
      "Epoch 335    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.569\n",
      "Epoch 336    / 2000   - loss = 1.657e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.569\n",
      "Epoch 337    / 2000   - loss = 1.657e+02 - val loss = 1.657e+02 -- est. noise std mean : 0.569\n",
      "Epoch 338    / 2000   - loss = 1.657e+02 - val loss = 1.657e+02 -- est. noise std mean : 0.568\n",
      "Epoch 339    / 2000   - loss = 1.658e+02 - val loss = 1.657e+02 -- est. noise std mean : 0.568\n",
      "Epoch 340    / 2000   - loss = 1.657e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.568\n",
      "Epoch 341    / 2000   - loss = 1.657e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.567\n",
      "Epoch 342    / 2000   - loss = 1.657e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.567\n",
      "Epoch 343    / 2000   - loss = 1.658e+02 - val loss = 1.657e+02 -- est. noise std mean : 0.567\n",
      "Epoch 344    / 2000   - loss = 1.657e+02 - val loss = 1.657e+02 -- est. noise std mean : 0.567\n",
      "Epoch 345    / 2000   - loss = 1.656e+02 - val loss = 1.657e+02 -- est. noise std mean : 0.567\n",
      "Epoch 346    / 2000   - loss = 1.657e+02 - val loss = 1.657e+02 -- est. noise std mean : 0.566\n",
      "Epoch 347    / 2000   - loss = 1.656e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.566\n",
      "Epoch 348    / 2000   - loss = 1.658e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.566\n",
      "Epoch 349    / 2000   - loss = 1.656e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.565\n",
      "Epoch 350    / 2000   - loss = 1.655e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.565\n",
      "Epoch 351    / 2000   - loss = 1.659e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.565\n",
      "Epoch 352    / 2000   - loss = 1.657e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.564\n",
      "Epoch 353    / 2000   - loss = 1.657e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.564\n",
      "Epoch 354    / 2000   - loss = 1.658e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.564\n",
      "Epoch 355    / 2000   - loss = 1.655e+02 - val loss = 1.659e+02 -- est. noise std mean : 0.564\n",
      "Epoch 356    / 2000   - loss = 1.654e+02 - val loss = 1.657e+02 -- est. noise std mean : 0.563\n",
      "Epoch 357    / 2000   - loss = 1.655e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.563\n",
      "Epoch 358    / 2000   - loss = 1.656e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.563\n",
      "Epoch 359    / 2000   - loss = 1.657e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.562\n",
      "Epoch 360    / 2000   - loss = 1.660e+02 - val loss = 1.659e+02 -- est. noise std mean : 0.562\n",
      "Epoch 361    / 2000   - loss = 1.655e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.562\n",
      "Epoch 362    / 2000   - loss = 1.659e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.562\n",
      "Epoch 363    / 2000   - loss = 1.654e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.562\n",
      "Epoch 364    / 2000   - loss = 1.656e+02 - val loss = 1.659e+02 -- est. noise std mean : 0.562\n",
      "Epoch 365    / 2000   - loss = 1.658e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.562\n",
      "Epoch 366    / 2000   - loss = 1.658e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.562\n",
      "Epoch 367    / 2000   - loss = 1.655e+02 - val loss = 1.657e+02 -- est. noise std mean : 0.562\n",
      "Epoch 368    / 2000   - loss = 1.656e+02 - val loss = 1.657e+02 -- est. noise std mean : 0.562\n",
      "Epoch 369    / 2000   - loss = 1.654e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.562\n",
      "Epoch 370    / 2000   - loss = 1.657e+02 - val loss = 1.659e+02 -- est. noise std mean : 0.562\n",
      "Epoch 371    / 2000   - loss = 1.656e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.562\n",
      "Epoch 372    / 2000   - loss = 1.658e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.562\n",
      "Epoch 373    / 2000   - loss = 1.656e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.562\n",
      "Epoch 374    / 2000   - loss = 1.657e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.563\n",
      "Epoch 375    / 2000   - loss = 1.657e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.563\n",
      "Epoch 376    / 2000   - loss = 1.656e+02 - val loss = 1.657e+02 -- est. noise std mean : 0.563\n",
      "Epoch 377    / 2000   - loss = 1.655e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.563\n",
      "Epoch 378    / 2000   - loss = 1.653e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.564\n",
      "Epoch 379    / 2000   - loss = 1.655e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.563\n",
      "Epoch 380    / 2000   - loss = 1.657e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.564\n",
      "Epoch 381    / 2000   - loss = 1.654e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.564\n",
      "Epoch 382    / 2000   - loss = 1.654e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.563\n",
      "Epoch 383    / 2000   - loss = 1.656e+02 - val loss = 1.657e+02 -- est. noise std mean : 0.563\n",
      "Epoch 384    / 2000   - loss = 1.657e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.564\n",
      "Epoch 385    / 2000   - loss = 1.657e+02 - val loss = 1.657e+02 -- est. noise std mean : 0.564\n",
      "Epoch 386    / 2000   - loss = 1.655e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.564\n",
      "Epoch 387    / 2000   - loss = 1.657e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.565\n",
      "Epoch 388    / 2000   - loss = 1.654e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.565\n",
      "Epoch 389    / 2000   - loss = 1.655e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.565\n",
      "Epoch 390    / 2000   - loss = 1.656e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.565\n",
      "Epoch 391    / 2000   - loss = 1.654e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.565\n",
      "Epoch 392    / 2000   - loss = 1.656e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.566\n",
      "Epoch 393    / 2000   - loss = 1.656e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.566\n",
      "Epoch 394    / 2000   - loss = 1.654e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.566\n",
      "Epoch 395    / 2000   - loss = 1.656e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.566\n",
      "Epoch 396    / 2000   - loss = 1.655e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.567\n",
      "Epoch 397    / 2000   - loss = 1.655e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.567\n",
      "Epoch 398    / 2000   - loss = 1.655e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.568\n",
      "Epoch 399    / 2000   - loss = 1.655e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.568\n",
      "Epoch 400    / 2000   - loss = 1.655e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.568\n",
      "Epoch 401    / 2000   - loss = 1.655e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.568\n",
      "Epoch 402    / 2000   - loss = 1.655e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.569\n",
      "Epoch 403    / 2000   - loss = 1.655e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.569\n",
      "Epoch 404    / 2000   - loss = 1.655e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.569\n",
      "Epoch 405    / 2000   - loss = 1.655e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.569\n",
      "Epoch 406    / 2000   - loss = 1.655e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.569\n",
      "Epoch 407    / 2000   - loss = 1.655e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.569\n",
      "Epoch 408    / 2000   - loss = 1.655e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.569\n",
      "Epoch 409    / 2000   - loss = 1.655e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.568\n",
      "Epoch 410    / 2000   - loss = 1.655e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.568\n",
      "Epoch 411    / 2000   - loss = 1.654e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.568\n",
      "Epoch 412    / 2000   - loss = 1.655e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.568\n",
      "Epoch 413    / 2000   - loss = 1.654e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.568\n",
      "Epoch 414    / 2000   - loss = 1.654e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.568\n",
      "Epoch 415    / 2000   - loss = 1.654e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.569\n",
      "Epoch 416    / 2000   - loss = 1.654e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.569\n",
      "Epoch 417    / 2000   - loss = 1.654e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.569\n",
      "Epoch 418    / 2000   - loss = 1.654e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.569\n",
      "Epoch 419    / 2000   - loss = 1.654e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.569\n",
      "Epoch 420    / 2000   - loss = 1.654e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.569\n",
      "Epoch 421    / 2000   - loss = 1.654e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.569\n",
      "Epoch 422    / 2000   - loss = 1.654e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.570\n",
      "Epoch 423    / 2000   - loss = 1.654e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.570\n",
      "Epoch 424    / 2000   - loss = 1.654e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.570\n",
      "Epoch 425    / 2000   - loss = 1.654e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.570\n",
      "Epoch 426    / 2000   - loss = 1.654e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.570\n",
      "Epoch 427    / 2000   - loss = 1.653e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.570\n",
      "Epoch 428    / 2000   - loss = 1.654e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.570\n",
      "Epoch 429    / 2000   - loss = 1.652e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.571\n",
      "Epoch 430    / 2000   - loss = 1.654e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.571\n",
      "Epoch 431    / 2000   - loss = 1.654e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.571\n",
      "Epoch 432    / 2000   - loss = 1.654e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.571\n",
      "Epoch 433    / 2000   - loss = 1.654e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.571\n",
      "Epoch 434    / 2000   - loss = 1.653e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.571\n",
      "Epoch 435    / 2000   - loss = 1.653e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.571\n",
      "Epoch 436    / 2000   - loss = 1.653e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.572\n",
      "Epoch 437    / 2000   - loss = 1.652e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.572\n",
      "Epoch 438    / 2000   - loss = 1.653e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.572\n",
      "Epoch 439    / 2000   - loss = 1.653e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.573\n",
      "Epoch 440    / 2000   - loss = 1.653e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.573\n",
      "Epoch 441    / 2000   - loss = 1.653e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.574\n",
      "Epoch 442    / 2000   - loss = 1.653e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.574\n",
      "Epoch 443    / 2000   - loss = 1.653e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.574\n",
      "Epoch 444    / 2000   - loss = 1.653e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.575\n",
      "Epoch 445    / 2000   - loss = 1.655e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.575\n",
      "Epoch 446    / 2000   - loss = 1.653e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.575\n",
      "Epoch 447    / 2000   - loss = 1.650e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.575\n",
      "Epoch 448    / 2000   - loss = 1.652e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.576\n",
      "Epoch 449    / 2000   - loss = 1.653e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.576\n",
      "Epoch 450    / 2000   - loss = 1.653e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.576\n",
      "Epoch 451    / 2000   - loss = 1.653e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.577\n",
      "Epoch 452    / 2000   - loss = 1.654e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.577\n",
      "Epoch 453    / 2000   - loss = 1.651e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.577\n",
      "Epoch 454    / 2000   - loss = 1.652e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.577\n",
      "Epoch 455    / 2000   - loss = 1.653e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.577\n",
      "Epoch 456    / 2000   - loss = 1.654e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.578\n",
      "Epoch 457    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.578\n",
      "Epoch 458    / 2000   - loss = 1.652e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.578\n",
      "Epoch 459    / 2000   - loss = 1.654e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.578\n",
      "Epoch 460    / 2000   - loss = 1.649e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.578\n",
      "Epoch 461    / 2000   - loss = 1.650e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.578\n",
      "Epoch 462    / 2000   - loss = 1.655e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.579\n",
      "Epoch 463    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.579\n",
      "Epoch 464    / 2000   - loss = 1.654e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.579\n",
      "Epoch 465    / 2000   - loss = 1.653e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.579\n",
      "Epoch 466    / 2000   - loss = 1.656e+02 - val loss = 1.659e+02 -- est. noise std mean : 0.579\n",
      "Epoch 467    / 2000   - loss = 1.653e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.579\n",
      "Epoch 468    / 2000   - loss = 1.656e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.578\n",
      "Epoch 469    / 2000   - loss = 1.652e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.578\n",
      "Epoch 470    / 2000   - loss = 1.653e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.578\n",
      "Epoch 471    / 2000   - loss = 1.655e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.577\n",
      "Epoch 472    / 2000   - loss = 1.654e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.577\n",
      "Epoch 473    / 2000   - loss = 1.654e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.576\n",
      "Epoch 474    / 2000   - loss = 1.654e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.575\n",
      "Epoch 475    / 2000   - loss = 1.650e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.575\n",
      "Epoch 476    / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.575\n",
      "Epoch 477    / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.574\n",
      "Epoch 478    / 2000   - loss = 1.652e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.574\n",
      "Epoch 479    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.574\n",
      "Epoch 480    / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.574\n",
      "Epoch 481    / 2000   - loss = 1.655e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.574\n",
      "Epoch 482    / 2000   - loss = 1.656e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.573\n",
      "Epoch 483    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.573\n",
      "Epoch 484    / 2000   - loss = 1.652e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.573\n",
      "Epoch 485    / 2000   - loss = 1.650e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.573\n",
      "Epoch 486    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.573\n",
      "Epoch 487    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.573\n",
      "Epoch 488    / 2000   - loss = 1.651e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.573\n",
      "Epoch 489    / 2000   - loss = 1.651e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.573\n",
      "Epoch 490    / 2000   - loss = 1.652e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.573\n",
      "Epoch 491    / 2000   - loss = 1.652e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.574\n",
      "Epoch 492    / 2000   - loss = 1.651e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.574\n",
      "Epoch 493    / 2000   - loss = 1.652e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.574\n",
      "Epoch 494    / 2000   - loss = 1.653e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.574\n",
      "Epoch 495    / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.574\n",
      "Epoch 496    / 2000   - loss = 1.652e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.574\n",
      "Epoch 497    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.574\n",
      "Epoch 498    / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.574\n",
      "Epoch 499    / 2000   - loss = 1.652e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.574\n",
      "Epoch 500    / 2000   - loss = 1.650e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.575\n",
      "Epoch 501    / 2000   - loss = 1.653e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.575\n",
      "Epoch 502    / 2000   - loss = 1.652e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.575\n",
      "Epoch 503    / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.575\n",
      "Epoch 504    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.575\n",
      "Epoch 505    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.575\n",
      "Epoch 506    / 2000   - loss = 1.651e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.576\n",
      "Epoch 507    / 2000   - loss = 1.653e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.576\n",
      "Epoch 508    / 2000   - loss = 1.652e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.576\n",
      "Epoch 509    / 2000   - loss = 1.652e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.576\n",
      "Epoch 510    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.576\n",
      "Epoch 511    / 2000   - loss = 1.652e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.576\n",
      "Epoch 512    / 2000   - loss = 1.649e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.576\n",
      "Epoch 513    / 2000   - loss = 1.653e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.576\n",
      "Epoch 514    / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.576\n",
      "Epoch 515    / 2000   - loss = 1.649e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.576\n",
      "Epoch 516    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.577\n",
      "Epoch 517    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.577\n",
      "Epoch 518    / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.577\n",
      "Epoch 519    / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.578\n",
      "Epoch 520    / 2000   - loss = 1.650e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.578\n",
      "Epoch 521    / 2000   - loss = 1.652e+02 - val loss = 1.659e+02 -- est. noise std mean : 0.578\n",
      "Epoch 522    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.578\n",
      "Epoch 523    / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.578\n",
      "Epoch 524    / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.579\n",
      "Epoch 525    / 2000   - loss = 1.652e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.579\n",
      "Epoch 526    / 2000   - loss = 1.649e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.579\n",
      "Epoch 527    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.579\n",
      "Epoch 528    / 2000   - loss = 1.652e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.579\n",
      "Epoch 529    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.580\n",
      "Epoch 530    / 2000   - loss = 1.655e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.580\n",
      "Epoch 531    / 2000   - loss = 1.648e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.580\n",
      "Epoch 532    / 2000   - loss = 1.651e+02 - val loss = 1.660e+02 -- est. noise std mean : 0.580\n",
      "Epoch 533    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.580\n",
      "Epoch 534    / 2000   - loss = 1.648e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.580\n",
      "Epoch 535    / 2000   - loss = 1.650e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.580\n",
      "Epoch 536    / 2000   - loss = 1.654e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.581\n",
      "Epoch 537    / 2000   - loss = 1.651e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.581\n",
      "Epoch 538    / 2000   - loss = 1.655e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.581\n",
      "Epoch 539    / 2000   - loss = 1.654e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.580\n",
      "Epoch 540    / 2000   - loss = 1.646e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.580\n",
      "Epoch 541    / 2000   - loss = 1.649e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.581\n",
      "Epoch 542    / 2000   - loss = 1.649e+02 - val loss = 1.663e+02 -- est. noise std mean : 0.581\n",
      "Epoch 543    / 2000   - loss = 1.653e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.581\n",
      "Epoch 544    / 2000   - loss = 1.654e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.581\n",
      "Epoch 545    / 2000   - loss = 1.655e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.581\n",
      "Epoch 546    / 2000   - loss = 1.650e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.581\n",
      "Epoch 547    / 2000   - loss = 1.653e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.581\n",
      "Epoch 548    / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.580\n",
      "Epoch 549    / 2000   - loss = 1.650e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.580\n",
      "Epoch 550    / 2000   - loss = 1.655e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.580\n",
      "Epoch 551    / 2000   - loss = 1.648e+02 - val loss = 1.647e+02 -- est. noise std mean : 0.580\n",
      "Epoch 552    / 2000   - loss = 1.652e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.580\n",
      "Epoch 553    / 2000   - loss = 1.649e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.579\n",
      "Epoch 554    / 2000   - loss = 1.650e+02 - val loss = 1.659e+02 -- est. noise std mean : 0.579\n",
      "Epoch 555    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.579\n",
      "Epoch 556    / 2000   - loss = 1.648e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.579\n",
      "Epoch 557    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.580\n",
      "Epoch 558    / 2000   - loss = 1.650e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.580\n",
      "Epoch 559    / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.580\n",
      "Epoch 560    / 2000   - loss = 1.653e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.580\n",
      "Epoch 561    / 2000   - loss = 1.652e+02 - val loss = 1.659e+02 -- est. noise std mean : 0.580\n",
      "Epoch 562    / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.580\n",
      "Epoch 563    / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.580\n",
      "Epoch 564    / 2000   - loss = 1.650e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.579\n",
      "Epoch 565    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.579\n",
      "Epoch 566    / 2000   - loss = 1.654e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.579\n",
      "Epoch 567    / 2000   - loss = 1.648e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.579\n",
      "Epoch 568    / 2000   - loss = 1.659e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.579\n",
      "Epoch 569    / 2000   - loss = 1.649e+02 - val loss = 1.657e+02 -- est. noise std mean : 0.579\n",
      "Epoch 570    / 2000   - loss = 1.656e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.578\n",
      "Epoch 571    / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.578\n",
      "Epoch 572    / 2000   - loss = 1.653e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.577\n",
      "Epoch 573    / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.577\n",
      "Epoch 574    / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.576\n",
      "Epoch 575    / 2000   - loss = 1.653e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.576\n",
      "Epoch 576    / 2000   - loss = 1.649e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.576\n",
      "Epoch 577    / 2000   - loss = 1.650e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.576\n",
      "Epoch 578    / 2000   - loss = 1.649e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.576\n",
      "Epoch 579    / 2000   - loss = 1.650e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.576\n",
      "Epoch 580    / 2000   - loss = 1.653e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.576\n",
      "Epoch 581    / 2000   - loss = 1.649e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.576\n",
      "Epoch 582    / 2000   - loss = 1.653e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.576\n",
      "Epoch 583    / 2000   - loss = 1.653e+02 - val loss = 1.659e+02 -- est. noise std mean : 0.576\n",
      "Epoch 584    / 2000   - loss = 1.649e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.576\n",
      "Epoch 585    / 2000   - loss = 1.653e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.576\n",
      "Epoch 586    / 2000   - loss = 1.651e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.576\n",
      "Epoch 587    / 2000   - loss = 1.653e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.576\n",
      "Epoch 588    / 2000   - loss = 1.656e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.576\n",
      "Epoch 589    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.575\n",
      "Epoch 590    / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.575\n",
      "Epoch 591    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.575\n",
      "Epoch 592    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.575\n",
      "Epoch 593    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.575\n",
      "Epoch 594    / 2000   - loss = 1.653e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.575\n",
      "Epoch 595    / 2000   - loss = 1.652e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.575\n",
      "Epoch 596    / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.574\n",
      "Epoch 597    / 2000   - loss = 1.654e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.574\n",
      "Epoch 598    / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.574\n",
      "Epoch 599    / 2000   - loss = 1.651e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.573\n",
      "Epoch 600    / 2000   - loss = 1.650e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.573\n",
      "Epoch 601    / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.573\n",
      "Epoch 602    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.572\n",
      "Epoch 603    / 2000   - loss = 1.651e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.572\n",
      "Epoch 604    / 2000   - loss = 1.651e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.572\n",
      "Epoch 605    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.572\n",
      "Epoch 606    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.572\n",
      "Epoch 607    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.572\n",
      "Epoch 608    / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.572\n",
      "Epoch 609    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.572\n",
      "Epoch 610    / 2000   - loss = 1.655e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.571\n",
      "Epoch 611    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 612    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 613    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 614    / 2000   - loss = 1.654e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 615    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 616    / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.569\n",
      "Epoch 617    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 618    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 619    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 620    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 621    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 622    / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.569\n",
      "Epoch 623    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 624    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 625    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 626    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 627    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 628    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 629    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 630    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 631    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 632    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 633    / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 634    / 2000   - loss = 1.656e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 635    / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.568\n",
      "Epoch 636    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 637    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 638    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 639    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 640    / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 641    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 642    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 643    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 644    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.564\n",
      "Epoch 645    / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.564\n",
      "Epoch 646    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.564\n",
      "Epoch 647    / 2000   - loss = 1.652e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.564\n",
      "Epoch 648    / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.564\n",
      "Epoch 649    / 2000   - loss = 1.650e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.564\n",
      "Epoch 650    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 651    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 652    / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.563\n",
      "Epoch 653    / 2000   - loss = 1.650e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.562\n",
      "Epoch 654    / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.562\n",
      "Epoch 655    / 2000   - loss = 1.654e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.562\n",
      "Epoch 656    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.562\n",
      "Epoch 657    / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.562\n",
      "Epoch 658    / 2000   - loss = 1.653e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.562\n",
      "Epoch 659    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.562\n",
      "Epoch 660    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 661    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 662    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 663    / 2000   - loss = 1.650e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.563\n",
      "Epoch 664    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 665    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.564\n",
      "Epoch 666    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.564\n",
      "Epoch 667    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 668    / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.563\n",
      "Epoch 669    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 670    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 671    / 2000   - loss = 1.650e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.563\n",
      "Epoch 672    / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.563\n",
      "Epoch 673    / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 674    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.562\n",
      "Epoch 675    / 2000   - loss = 1.650e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.562\n",
      "Epoch 676    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.561\n",
      "Epoch 677    / 2000   - loss = 1.653e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.561\n",
      "Epoch 678    / 2000   - loss = 1.653e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.561\n",
      "Epoch 679    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.561\n",
      "Epoch 680    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.562\n",
      "Epoch 681    / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.562\n",
      "Epoch 682    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.562\n",
      "Epoch 683    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 684    / 2000   - loss = 1.650e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.563\n",
      "Epoch 685    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 686    / 2000   - loss = 1.653e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.563\n",
      "Epoch 687    / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.563\n",
      "Epoch 688    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 689    / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.564\n",
      "Epoch 690    / 2000   - loss = 1.650e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.564\n",
      "Epoch 691    / 2000   - loss = 1.652e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.564\n",
      "Epoch 692    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 693    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 694    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 695    / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.565\n",
      "Epoch 696    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 697    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 698    / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.564\n",
      "Epoch 699    / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.564\n",
      "Epoch 700    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.564\n",
      "Epoch 701    / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.564\n",
      "Epoch 702    / 2000   - loss = 1.652e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.564\n",
      "Epoch 703    / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.564\n",
      "Epoch 704    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 705    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 706    / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 707    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 708    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 709    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 710    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 711    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 712    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 713    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 714    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 715    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 716    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 717    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 718    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 719    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 720    / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 721    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 722    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 723    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.569\n",
      "Epoch 724    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 725    / 2000   - loss = 1.652e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.570\n",
      "Epoch 726    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 727    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 728    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 729    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 730    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 731    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 732    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 733    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.571\n",
      "Epoch 734    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 735    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 736    / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 737    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 738    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 739    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 740    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 741    / 2000   - loss = 1.650e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.570\n",
      "Epoch 742    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.571\n",
      "Epoch 743    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 744    / 2000   - loss = 1.650e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.571\n",
      "Epoch 745    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.571\n",
      "Epoch 746    / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.571\n",
      "Epoch 747    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.572\n",
      "Epoch 748    / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.572\n",
      "Epoch 749    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.572\n",
      "Epoch 750    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.572\n",
      "Epoch 751    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.572\n",
      "Epoch 752    / 2000   - loss = 1.653e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.572\n",
      "Epoch 753    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.572\n",
      "Epoch 754    / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.571\n",
      "Epoch 755    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 756    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 757    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 758    / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.571\n",
      "Epoch 759    / 2000   - loss = 1.651e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.570\n",
      "Epoch 760    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 761    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 762    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 763    / 2000   - loss = 1.650e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.570\n",
      "Epoch 764    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 765    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 766    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 767    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.571\n",
      "Epoch 768    / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 769    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 770    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 771    / 2000   - loss = 1.655e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 772    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 773    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 774    / 2000   - loss = 1.651e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.570\n",
      "Epoch 775    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.571\n",
      "Epoch 776    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 777    / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.571\n",
      "Epoch 778    / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.572\n",
      "Epoch 779    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.572\n",
      "Epoch 780    / 2000   - loss = 1.651e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.572\n",
      "Epoch 781    / 2000   - loss = 1.656e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.572\n",
      "Epoch 782    / 2000   - loss = 1.650e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.572\n",
      "Epoch 783    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.572\n",
      "Epoch 784    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.571\n",
      "Epoch 785    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 786    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 787    / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.571\n",
      "Epoch 788    / 2000   - loss = 1.650e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.571\n",
      "Epoch 789    / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 790    / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.572\n",
      "Epoch 791    / 2000   - loss = 1.650e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.572\n",
      "Epoch 792    / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.573\n",
      "Epoch 793    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.573\n",
      "Epoch 794    / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.574\n",
      "Epoch 795    / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.574\n",
      "Epoch 796    / 2000   - loss = 1.647e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.574\n",
      "Epoch 797    / 2000   - loss = 1.654e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.575\n",
      "Epoch 798    / 2000   - loss = 1.649e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.575\n",
      "Epoch 799    / 2000   - loss = 1.653e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.575\n",
      "Epoch 800    / 2000   - loss = 1.653e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.575\n",
      "Epoch 801    / 2000   - loss = 1.653e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.574\n",
      "Epoch 802    / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.574\n",
      "Epoch 803    / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.574\n",
      "Epoch 804    / 2000   - loss = 1.652e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.573\n",
      "Epoch 805    / 2000   - loss = 1.650e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.573\n",
      "Epoch 806    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.573\n",
      "Epoch 807    / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.573\n",
      "Epoch 808    / 2000   - loss = 1.650e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.573\n",
      "Epoch 809    / 2000   - loss = 1.652e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.573\n",
      "Epoch 810    / 2000   - loss = 1.648e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.573\n",
      "Epoch 811    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.573\n",
      "Epoch 812    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.573\n",
      "Epoch 813    / 2000   - loss = 1.649e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.573\n",
      "Epoch 814    / 2000   - loss = 1.650e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.574\n",
      "Epoch 815    / 2000   - loss = 1.648e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.574\n",
      "Epoch 816    / 2000   - loss = 1.650e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.575\n",
      "Epoch 817    / 2000   - loss = 1.651e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.576\n",
      "Epoch 818    / 2000   - loss = 1.653e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.576\n",
      "Epoch 819    / 2000   - loss = 1.648e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.577\n",
      "Epoch 820    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.577\n",
      "Epoch 821    / 2000   - loss = 1.653e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.577\n",
      "Epoch 822    / 2000   - loss = 1.654e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.577\n",
      "Epoch 823    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.577\n",
      "Epoch 824    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.577\n",
      "Epoch 825    / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.577\n",
      "Epoch 826    / 2000   - loss = 1.650e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.577\n",
      "Epoch 827    / 2000   - loss = 1.654e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.577\n",
      "Epoch 828    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.577\n",
      "Epoch 829    / 2000   - loss = 1.648e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.577\n",
      "Epoch 830    / 2000   - loss = 1.653e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.577\n",
      "Epoch 831    / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.577\n",
      "Epoch 832    / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.577\n",
      "Epoch 833    / 2000   - loss = 1.652e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.577\n",
      "Epoch 834    / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.576\n",
      "Epoch 835    / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.576\n",
      "Epoch 836    / 2000   - loss = 1.648e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.576\n",
      "Epoch 837    / 2000   - loss = 1.652e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.575\n",
      "Epoch 838    / 2000   - loss = 1.653e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.575\n",
      "Epoch 839    / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.574\n",
      "Epoch 840    / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.574\n",
      "Epoch 841    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.573\n",
      "Epoch 842    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.573\n",
      "Epoch 843    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.572\n",
      "Epoch 844    / 2000   - loss = 1.653e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.571\n",
      "Epoch 845    / 2000   - loss = 1.650e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.571\n",
      "Epoch 846    / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 847    / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 848    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 849    / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 850    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 851    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 852    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 853    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 854    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 855    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 856    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 857    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 858    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 859    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 860    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 861    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.567\n",
      "Epoch 862    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 863    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 864    / 2000   - loss = 1.651e+02 - val loss = 1.647e+02 -- est. noise std mean : 0.567\n",
      "Epoch 865    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 866    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 867    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 868    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 869    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 870    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 871    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 872    / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.566\n",
      "Epoch 873    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 874    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 875    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 876    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 877    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 878    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 879    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 880    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 881    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 882    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 883    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 884    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 885    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 886    / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.566\n",
      "Epoch 887    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 888    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 889    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 890    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 891    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 892    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 893    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 894    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 895    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 896    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 897    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.564\n",
      "Epoch 898    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.564\n",
      "Epoch 899    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.564\n",
      "Epoch 900    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.564\n",
      "Epoch 901    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 902    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 903    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 904    / 2000   - loss = 1.650e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.563\n",
      "Epoch 905    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.562\n",
      "Epoch 906    / 2000   - loss = 1.653e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.562\n",
      "Epoch 907    / 2000   - loss = 1.649e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.562\n",
      "Epoch 908    / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.562\n",
      "Epoch 909    / 2000   - loss = 1.652e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.562\n",
      "Epoch 910    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.562\n",
      "Epoch 911    / 2000   - loss = 1.651e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.562\n",
      "Epoch 912    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.562\n",
      "Epoch 913    / 2000   - loss = 1.652e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.562\n",
      "Epoch 914    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.562\n",
      "Epoch 915    / 2000   - loss = 1.649e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.562\n",
      "Epoch 916    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.562\n",
      "Epoch 917    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.562\n",
      "Epoch 918    / 2000   - loss = 1.652e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.562\n",
      "Epoch 919    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 920    / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.563\n",
      "Epoch 921    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 922    / 2000   - loss = 1.649e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.563\n",
      "Epoch 923    / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.562\n",
      "Epoch 924    / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.562\n",
      "Epoch 925    / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.562\n",
      "Epoch 926    / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.561\n",
      "Epoch 927    / 2000   - loss = 1.649e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.561\n",
      "Epoch 928    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.561\n",
      "Epoch 929    / 2000   - loss = 1.649e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.560\n",
      "Epoch 930    / 2000   - loss = 1.649e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.560\n",
      "Epoch 931    / 2000   - loss = 1.650e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.559\n",
      "Epoch 932    / 2000   - loss = 1.650e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.559\n",
      "Epoch 933    / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.559\n",
      "Epoch 934    / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.558\n",
      "Epoch 935    / 2000   - loss = 1.653e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.558\n",
      "Epoch 936    / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.558\n",
      "Epoch 937    / 2000   - loss = 1.649e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.558\n",
      "Epoch 938    / 2000   - loss = 1.652e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.558\n",
      "Epoch 939    / 2000   - loss = 1.655e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.559\n",
      "Epoch 940    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.559\n",
      "Epoch 941    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.560\n",
      "Epoch 942    / 2000   - loss = 1.649e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.560\n",
      "Epoch 943    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.560\n",
      "Epoch 944    / 2000   - loss = 1.649e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.561\n",
      "Epoch 945    / 2000   - loss = 1.649e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.561\n",
      "Epoch 946    / 2000   - loss = 1.648e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.560\n",
      "Epoch 947    / 2000   - loss = 1.649e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.560\n",
      "Epoch 948    / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.559\n",
      "Epoch 949    / 2000   - loss = 1.652e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.559\n",
      "Epoch 950    / 2000   - loss = 1.653e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.559\n",
      "Epoch 951    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.559\n",
      "Epoch 952    / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.560\n",
      "Epoch 953    / 2000   - loss = 1.650e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.560\n",
      "Epoch 954    / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.560\n",
      "Epoch 955    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.560\n",
      "Epoch 956    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.560\n",
      "Epoch 957    / 2000   - loss = 1.653e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.560\n",
      "Epoch 958    / 2000   - loss = 1.654e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.561\n",
      "Epoch 959    / 2000   - loss = 1.649e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.561\n",
      "Epoch 960    / 2000   - loss = 1.655e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.562\n",
      "Epoch 961    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 962    / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 963    / 2000   - loss = 1.650e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.563\n",
      "Epoch 964    / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 965    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 966    / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 967    / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.564\n",
      "Epoch 968    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.564\n",
      "Epoch 969    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.564\n",
      "Epoch 970    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.564\n",
      "Epoch 971    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.564\n",
      "Epoch 972    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.564\n",
      "Epoch 973    / 2000   - loss = 1.650e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.564\n",
      "Epoch 974    / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.565\n",
      "Epoch 975    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 976    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 977    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 978    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 979    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 980    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 981    / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 982    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.564\n",
      "Epoch 983    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 984    / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 985    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 986    / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 987    / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.563\n",
      "Epoch 988    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 989    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 990    / 2000   - loss = 1.648e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 991    / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 992    / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.563\n",
      "Epoch 993    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 994    / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 995    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 996    / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 997    / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 998    / 2000   - loss = 1.649e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 999    / 2000   - loss = 1.647e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1000   / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1001   / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1002   / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1003   / 2000   - loss = 1.652e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1004   / 2000   - loss = 1.651e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1005   / 2000   - loss = 1.650e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1006   / 2000   - loss = 1.652e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1007   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1008   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1009   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1010   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1011   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1012   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1013   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1014   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1015   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1016   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1017   / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1018   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1019   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1020   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1021   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1022   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1023   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1024   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1025   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1026   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1027   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1028   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1029   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1030   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1031   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1032   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1033   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1034   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1035   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1036   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1037   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1038   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1039   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1040   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1041   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1042   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1043   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1044   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1045   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1046   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1047   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1048   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1049   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1050   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1051   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1052   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1053   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1054   / 2000   - loss = 1.650e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1055   / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1056   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.572\n",
      "Epoch 1057   / 2000   - loss = 1.649e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.572\n",
      "Epoch 1058   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.573\n",
      "Epoch 1059   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.574\n",
      "Epoch 1060   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.575\n",
      "Epoch 1061   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.575\n",
      "Epoch 1062   / 2000   - loss = 1.649e+02 - val loss = 1.647e+02 -- est. noise std mean : 0.576\n",
      "Epoch 1063   / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.577\n",
      "Epoch 1064   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.577\n",
      "Epoch 1065   / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.578\n",
      "Epoch 1066   / 2000   - loss = 1.653e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.578\n",
      "Epoch 1067   / 2000   - loss = 1.650e+02 - val loss = 1.646e+02 -- est. noise std mean : 0.578\n",
      "Epoch 1068   / 2000   - loss = 1.652e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.578\n",
      "Epoch 1069   / 2000   - loss = 1.649e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.578\n",
      "Epoch 1070   / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.578\n",
      "Epoch 1071   / 2000   - loss = 1.652e+02 - val loss = 1.647e+02 -- est. noise std mean : 0.577\n",
      "Epoch 1072   / 2000   - loss = 1.645e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.578\n",
      "Epoch 1073   / 2000   - loss = 1.650e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.578\n",
      "Epoch 1074   / 2000   - loss = 1.653e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.578\n",
      "Epoch 1075   / 2000   - loss = 1.651e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.578\n",
      "Epoch 1076   / 2000   - loss = 1.648e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.578\n",
      "Epoch 1077   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.578\n",
      "Epoch 1078   / 2000   - loss = 1.649e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.579\n",
      "Epoch 1079   / 2000   - loss = 1.649e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.579\n",
      "Epoch 1080   / 2000   - loss = 1.649e+02 - val loss = 1.644e+02 -- est. noise std mean : 0.579\n",
      "Epoch 1081   / 2000   - loss = 1.649e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.580\n",
      "Epoch 1082   / 2000   - loss = 1.660e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.580\n",
      "Epoch 1083   / 2000   - loss = 1.657e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.579\n",
      "Epoch 1084   / 2000   - loss = 1.648e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.578\n",
      "Epoch 1085   / 2000   - loss = 1.656e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.578\n",
      "Epoch 1086   / 2000   - loss = 1.646e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.577\n",
      "Epoch 1087   / 2000   - loss = 1.653e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.577\n",
      "Epoch 1088   / 2000   - loss = 1.650e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.576\n",
      "Epoch 1089   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.575\n",
      "Epoch 1090   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.575\n",
      "Epoch 1091   / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.574\n",
      "Epoch 1092   / 2000   - loss = 1.653e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.574\n",
      "Epoch 1093   / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.572\n",
      "Epoch 1094   / 2000   - loss = 1.648e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.572\n",
      "Epoch 1095   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1096   / 2000   - loss = 1.647e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1097   / 2000   - loss = 1.648e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.572\n",
      "Epoch 1098   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.572\n",
      "Epoch 1099   / 2000   - loss = 1.649e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.572\n",
      "Epoch 1100   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.573\n",
      "Epoch 1101   / 2000   - loss = 1.651e+02 - val loss = 1.643e+02 -- est. noise std mean : 0.573\n",
      "Epoch 1102   / 2000   - loss = 1.652e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.573\n",
      "Epoch 1103   / 2000   - loss = 1.652e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.573\n",
      "Epoch 1104   / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.573\n",
      "Epoch 1105   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.573\n",
      "Epoch 1106   / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.573\n",
      "Epoch 1107   / 2000   - loss = 1.648e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.573\n",
      "Epoch 1108   / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.572\n",
      "Epoch 1109   / 2000   - loss = 1.652e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.572\n",
      "Epoch 1110   / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1111   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1112   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1113   / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1114   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1115   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1116   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1117   / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1118   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1119   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1120   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1121   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1122   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1123   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1124   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1125   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1126   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1127   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1128   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1129   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1130   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1131   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1132   / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1133   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1134   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1135   / 2000   - loss = 1.650e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1136   / 2000   - loss = 1.651e+02 - val loss = 1.646e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1137   / 2000   - loss = 1.650e+02 - val loss = 1.647e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1138   / 2000   - loss = 1.647e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1139   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1140   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1141   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1142   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1143   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1144   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1145   / 2000   - loss = 1.650e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1146   / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1147   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1148   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1149   / 2000   - loss = 1.649e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1150   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1151   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1152   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1153   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1154   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1155   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1156   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1157   / 2000   - loss = 1.650e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1158   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1159   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1160   / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1161   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1162   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1163   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1164   / 2000   - loss = 1.651e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1165   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1166   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1167   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1168   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1169   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1170   / 2000   - loss = 1.650e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1171   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1172   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1173   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1174   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1175   / 2000   - loss = 1.649e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1176   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1177   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1178   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1179   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1180   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1181   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1182   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1183   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1184   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1185   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1186   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1187   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1188   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1189   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1190   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1191   / 2000   - loss = 1.648e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1192   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1193   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1194   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1195   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1196   / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1197   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1198   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1199   / 2000   - loss = 1.652e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1200   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1201   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1202   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1203   / 2000   - loss = 1.646e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1204   / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1205   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1206   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1207   / 2000   - loss = 1.652e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1208   / 2000   - loss = 1.651e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1209   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1210   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1211   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1212   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1213   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1214   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1215   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1216   / 2000   - loss = 1.651e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1217   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1218   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1219   / 2000   - loss = 1.649e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1220   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1221   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1222   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1223   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1224   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1225   / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1226   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1227   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1228   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1229   / 2000   - loss = 1.651e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1230   / 2000   - loss = 1.648e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1231   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1232   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1233   / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1234   / 2000   - loss = 1.648e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1235   / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1236   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1237   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1238   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1239   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1240   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1241   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1242   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1243   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1244   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1245   / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1246   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1247   / 2000   - loss = 1.648e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1248   / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1249   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1250   / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1251   / 2000   - loss = 1.647e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1252   / 2000   - loss = 1.648e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.558\n",
      "Epoch 1253   / 2000   - loss = 1.652e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.558\n",
      "Epoch 1254   / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.557\n",
      "Epoch 1255   / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.557\n",
      "Epoch 1256   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.557\n",
      "Epoch 1257   / 2000   - loss = 1.652e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.556\n",
      "Epoch 1258   / 2000   - loss = 1.650e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.556\n",
      "Epoch 1259   / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.556\n",
      "Epoch 1260   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.556\n",
      "Epoch 1261   / 2000   - loss = 1.648e+02 - val loss = 1.644e+02 -- est. noise std mean : 0.555\n",
      "Epoch 1262   / 2000   - loss = 1.652e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.555\n",
      "Epoch 1263   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.555\n",
      "Epoch 1264   / 2000   - loss = 1.652e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.555\n",
      "Epoch 1265   / 2000   - loss = 1.651e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.555\n",
      "Epoch 1266   / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.555\n",
      "Epoch 1267   / 2000   - loss = 1.652e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.556\n",
      "Epoch 1268   / 2000   - loss = 1.650e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.556\n",
      "Epoch 1269   / 2000   - loss = 1.649e+02 - val loss = 1.647e+02 -- est. noise std mean : 0.556\n",
      "Epoch 1270   / 2000   - loss = 1.647e+02 - val loss = 1.647e+02 -- est. noise std mean : 0.555\n",
      "Epoch 1271   / 2000   - loss = 1.648e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.555\n",
      "Epoch 1272   / 2000   - loss = 1.648e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.555\n",
      "Epoch 1273   / 2000   - loss = 1.652e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.554\n",
      "Epoch 1274   / 2000   - loss = 1.654e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.554\n",
      "Epoch 1275   / 2000   - loss = 1.648e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.554\n",
      "Epoch 1276   / 2000   - loss = 1.653e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.555\n",
      "Epoch 1277   / 2000   - loss = 1.644e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.554\n",
      "Epoch 1278   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.554\n",
      "Epoch 1279   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.554\n",
      "Epoch 1280   / 2000   - loss = 1.652e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.554\n",
      "Epoch 1281   / 2000   - loss = 1.655e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.554\n",
      "Epoch 1282   / 2000   - loss = 1.650e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.555\n",
      "Epoch 1283   / 2000   - loss = 1.650e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.555\n",
      "Epoch 1284   / 2000   - loss = 1.654e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.555\n",
      "Epoch 1285   / 2000   - loss = 1.651e+02 - val loss = 1.643e+02 -- est. noise std mean : 0.556\n",
      "Epoch 1286   / 2000   - loss = 1.648e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.556\n",
      "Epoch 1287   / 2000   - loss = 1.653e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.557\n",
      "Epoch 1288   / 2000   - loss = 1.654e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.558\n",
      "Epoch 1289   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.558\n",
      "Epoch 1290   / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1291   / 2000   - loss = 1.653e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1292   / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1293   / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1294   / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1295   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1296   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1297   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1298   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1299   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1300   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1301   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1302   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1303   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1304   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1305   / 2000   - loss = 1.650e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1306   / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1307   / 2000   - loss = 1.650e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1308   / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1309   / 2000   - loss = 1.652e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1310   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1311   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1312   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1313   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1314   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1315   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1316   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1317   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1318   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1319   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1320   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1321   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1322   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1323   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1324   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1325   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1326   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1327   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1328   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1329   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1330   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1331   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1332   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1333   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1334   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1335   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1336   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1337   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1338   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1339   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1340   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1341   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1342   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1343   / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1344   / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.572\n",
      "Epoch 1345   / 2000   - loss = 1.650e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.573\n",
      "Epoch 1346   / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.573\n",
      "Epoch 1347   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.574\n",
      "Epoch 1348   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.574\n",
      "Epoch 1349   / 2000   - loss = 1.649e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.575\n",
      "Epoch 1350   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.576\n",
      "Epoch 1351   / 2000   - loss = 1.649e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.577\n",
      "Epoch 1352   / 2000   - loss = 1.646e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.578\n",
      "Epoch 1353   / 2000   - loss = 1.652e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.579\n",
      "Epoch 1354   / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.580\n",
      "Epoch 1355   / 2000   - loss = 1.654e+02 - val loss = 1.646e+02 -- est. noise std mean : 0.580\n",
      "Epoch 1356   / 2000   - loss = 1.663e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.580\n",
      "Epoch 1357   / 2000   - loss = 1.650e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.580\n",
      "Epoch 1358   / 2000   - loss = 1.652e+02 - val loss = 1.647e+02 -- est. noise std mean : 0.579\n",
      "Epoch 1359   / 2000   - loss = 1.651e+02 - val loss = 1.647e+02 -- est. noise std mean : 0.579\n",
      "Epoch 1360   / 2000   - loss = 1.650e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.578\n",
      "Epoch 1361   / 2000   - loss = 1.655e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.578\n",
      "Epoch 1362   / 2000   - loss = 1.653e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.577\n",
      "Epoch 1363   / 2000   - loss = 1.653e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.576\n",
      "Epoch 1364   / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.575\n",
      "Epoch 1365   / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.574\n",
      "Epoch 1366   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.573\n",
      "Epoch 1367   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.572\n",
      "Epoch 1368   / 2000   - loss = 1.649e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1369   / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1370   / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1371   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1372   / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1373   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1374   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1375   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1376   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1377   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1378   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1379   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1380   / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1381   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1382   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1383   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1384   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1385   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.572\n",
      "Epoch 1386   / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.572\n",
      "Epoch 1387   / 2000   - loss = 1.652e+02 - val loss = 1.647e+02 -- est. noise std mean : 0.572\n",
      "Epoch 1388   / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.572\n",
      "Epoch 1389   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.572\n",
      "Epoch 1390   / 2000   - loss = 1.649e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.572\n",
      "Epoch 1391   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.573\n",
      "Epoch 1392   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.573\n",
      "Epoch 1393   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.574\n",
      "Epoch 1394   / 2000   - loss = 1.652e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.574\n",
      "Epoch 1395   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.573\n",
      "Epoch 1396   / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.573\n",
      "Epoch 1397   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.573\n",
      "Epoch 1398   / 2000   - loss = 1.649e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.573\n",
      "Epoch 1399   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.573\n",
      "Epoch 1400   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.573\n",
      "Epoch 1401   / 2000   - loss = 1.650e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.573\n",
      "Epoch 1402   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.572\n",
      "Epoch 1403   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.572\n",
      "Epoch 1404   / 2000   - loss = 1.653e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1405   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1406   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1407   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1408   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1409   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1410   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1411   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1412   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1413   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1414   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1415   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1416   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1417   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1418   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1419   / 2000   - loss = 1.649e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1420   / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1421   / 2000   - loss = 1.649e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1422   / 2000   - loss = 1.649e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1423   / 2000   - loss = 1.653e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1424   / 2000   - loss = 1.650e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1425   / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1426   / 2000   - loss = 1.649e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1427   / 2000   - loss = 1.649e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1428   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1429   / 2000   - loss = 1.649e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1430   / 2000   - loss = 1.652e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1431   / 2000   - loss = 1.653e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1432   / 2000   - loss = 1.652e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1433   / 2000   - loss = 1.654e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1434   / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1435   / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1436   / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1437   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1438   / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1439   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1440   / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1441   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1442   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1443   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1444   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1445   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1446   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1447   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1448   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1449   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1450   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1451   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1452   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1453   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1454   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1455   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1456   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1457   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1458   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1459   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1460   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1461   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1462   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1463   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1464   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1465   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1466   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1467   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1468   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1469   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1470   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1471   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1472   / 2000   - loss = 1.654e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1473   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1474   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1475   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1476   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1477   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1478   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1479   / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1480   / 2000   - loss = 1.650e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1481   / 2000   - loss = 1.653e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1482   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1483   / 2000   - loss = 1.654e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1484   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1485   / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1486   / 2000   - loss = 1.648e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1487   / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1488   / 2000   - loss = 1.650e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1489   / 2000   - loss = 1.650e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1490   / 2000   - loss = 1.654e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1491   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1492   / 2000   - loss = 1.650e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1493   / 2000   - loss = 1.652e+02 - val loss = 1.647e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1494   / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1495   / 2000   - loss = 1.648e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1496   / 2000   - loss = 1.648e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1497   / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1498   / 2000   - loss = 1.653e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1499   / 2000   - loss = 1.652e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1500   / 2000   - loss = 1.648e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1501   / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1502   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1503   / 2000   - loss = 1.650e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1504   / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1505   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1506   / 2000   - loss = 1.653e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1507   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1508   / 2000   - loss = 1.652e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1509   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1510   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1511   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1512   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1513   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1514   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1515   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1516   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1517   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1518   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1519   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1520   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1521   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1522   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1523   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1524   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1525   / 2000   - loss = 1.650e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1526   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1527   / 2000   - loss = 1.652e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1528   / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1529   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1530   / 2000   - loss = 1.652e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1531   / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1532   / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1533   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1534   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1535   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1536   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1537   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1538   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1539   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1540   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1541   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1542   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1543   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1544   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1545   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1546   / 2000   - loss = 1.649e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1547   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.572\n",
      "Epoch 1548   / 2000   - loss = 1.649e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.573\n",
      "Epoch 1549   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.574\n",
      "Epoch 1550   / 2000   - loss = 1.651e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.575\n",
      "Epoch 1551   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.575\n",
      "Epoch 1552   / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.576\n",
      "Epoch 1553   / 2000   - loss = 1.652e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.576\n",
      "Epoch 1554   / 2000   - loss = 1.649e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.576\n",
      "Epoch 1555   / 2000   - loss = 1.652e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.576\n",
      "Epoch 1556   / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.576\n",
      "Epoch 1557   / 2000   - loss = 1.651e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.576\n",
      "Epoch 1558   / 2000   - loss = 1.655e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.576\n",
      "Epoch 1559   / 2000   - loss = 1.647e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.576\n",
      "Epoch 1560   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.576\n",
      "Epoch 1561   / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.576\n",
      "Epoch 1562   / 2000   - loss = 1.651e+02 - val loss = 1.646e+02 -- est. noise std mean : 0.576\n",
      "Epoch 1563   / 2000   - loss = 1.652e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.576\n",
      "Epoch 1564   / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.575\n",
      "Epoch 1565   / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.575\n",
      "Epoch 1566   / 2000   - loss = 1.649e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.574\n",
      "Epoch 1567   / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.574\n",
      "Epoch 1568   / 2000   - loss = 1.651e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.573\n",
      "Epoch 1569   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.573\n",
      "Epoch 1570   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.572\n",
      "Epoch 1571   / 2000   - loss = 1.654e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1572   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1573   / 2000   - loss = 1.651e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1574   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1575   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1576   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1577   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1578   / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1579   / 2000   - loss = 1.652e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1580   / 2000   - loss = 1.649e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1581   / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1582   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1583   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1584   / 2000   - loss = 1.649e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1585   / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1586   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1587   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1588   / 2000   - loss = 1.650e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1589   / 2000   - loss = 1.652e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1590   / 2000   - loss = 1.652e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1591   / 2000   - loss = 1.649e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1592   / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1593   / 2000   - loss = 1.650e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1594   / 2000   - loss = 1.649e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1595   / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1596   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1597   / 2000   - loss = 1.650e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1598   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1599   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1600   / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1601   / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1602   / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1603   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1604   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1605   / 2000   - loss = 1.653e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1606   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1607   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1608   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1609   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1610   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1611   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1612   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1613   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1614   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1615   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1616   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1617   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1618   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1619   / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1620   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1621   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1622   / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1623   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1624   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1625   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1626   / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1627   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1628   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1629   / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1630   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1631   / 2000   - loss = 1.651e+02 - val loss = 1.646e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1632   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1633   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1634   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1635   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1636   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1637   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1638   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1639   / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1640   / 2000   - loss = 1.645e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1641   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1642   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1643   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.572\n",
      "Epoch 1644   / 2000   - loss = 1.651e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.573\n",
      "Epoch 1645   / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.573\n",
      "Epoch 1646   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.574\n",
      "Epoch 1647   / 2000   - loss = 1.648e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.575\n",
      "Epoch 1648   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.576\n",
      "Epoch 1649   / 2000   - loss = 1.652e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.576\n",
      "Epoch 1650   / 2000   - loss = 1.650e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.577\n",
      "Epoch 1651   / 2000   - loss = 1.648e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.578\n",
      "Epoch 1652   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.578\n",
      "Epoch 1653   / 2000   - loss = 1.652e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.579\n",
      "Epoch 1654   / 2000   - loss = 1.654e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.579\n",
      "Epoch 1655   / 2000   - loss = 1.653e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.578\n",
      "Epoch 1656   / 2000   - loss = 1.646e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.578\n",
      "Epoch 1657   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.578\n",
      "Epoch 1658   / 2000   - loss = 1.653e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.578\n",
      "Epoch 1659   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.578\n",
      "Epoch 1660   / 2000   - loss = 1.653e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.578\n",
      "Epoch 1661   / 2000   - loss = 1.651e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.577\n",
      "Epoch 1662   / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.577\n",
      "Epoch 1663   / 2000   - loss = 1.653e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.576\n",
      "Epoch 1664   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.575\n",
      "Epoch 1665   / 2000   - loss = 1.652e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.574\n",
      "Epoch 1666   / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.573\n",
      "Epoch 1667   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.572\n",
      "Epoch 1668   / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1669   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1670   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1671   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1672   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1673   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1674   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1675   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1676   / 2000   - loss = 1.648e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1677   / 2000   - loss = 1.651e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1678   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1679   / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1680   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1681   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1682   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1683   / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.572\n",
      "Epoch 1684   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.573\n",
      "Epoch 1685   / 2000   - loss = 1.651e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.574\n",
      "Epoch 1686   / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.574\n",
      "Epoch 1687   / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.574\n",
      "Epoch 1688   / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.574\n",
      "Epoch 1689   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.574\n",
      "Epoch 1690   / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.574\n",
      "Epoch 1691   / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.574\n",
      "Epoch 1692   / 2000   - loss = 1.652e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.574\n",
      "Epoch 1693   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.573\n",
      "Epoch 1694   / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.573\n",
      "Epoch 1695   / 2000   - loss = 1.653e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.572\n",
      "Epoch 1696   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1697   / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1698   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1699   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1700   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1701   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1702   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1703   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1704   / 2000   - loss = 1.649e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1705   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1706   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1707   / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1708   / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1709   / 2000   - loss = 1.647e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1710   / 2000   - loss = 1.652e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.558\n",
      "Epoch 1711   / 2000   - loss = 1.649e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.557\n",
      "Epoch 1712   / 2000   - loss = 1.650e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.556\n",
      "Epoch 1713   / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.556\n",
      "Epoch 1714   / 2000   - loss = 1.653e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.555\n",
      "Epoch 1715   / 2000   - loss = 1.648e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.555\n",
      "Epoch 1716   / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.555\n",
      "Epoch 1717   / 2000   - loss = 1.653e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.555\n",
      "Epoch 1718   / 2000   - loss = 1.653e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.555\n",
      "Epoch 1719   / 2000   - loss = 1.656e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.556\n",
      "Epoch 1720   / 2000   - loss = 1.654e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.557\n",
      "Epoch 1721   / 2000   - loss = 1.654e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.558\n",
      "Epoch 1722   / 2000   - loss = 1.648e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1723   / 2000   - loss = 1.653e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1724   / 2000   - loss = 1.652e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1725   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1726   / 2000   - loss = 1.649e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1727   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1728   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1729   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1730   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1731   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1732   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1733   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1734   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1735   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1736   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1737   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1738   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1739   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1740   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1741   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1742   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1743   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1744   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1745   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1746   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1747   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1748   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1749   / 2000   - loss = 1.649e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1750   / 2000   - loss = 1.649e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1751   / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1752   / 2000   - loss = 1.652e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1753   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1754   / 2000   - loss = 1.650e+02 - val loss = 1.647e+02 -- est. noise std mean : 0.558\n",
      "Epoch 1755   / 2000   - loss = 1.653e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.558\n",
      "Epoch 1756   / 2000   - loss = 1.648e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.558\n",
      "Epoch 1757   / 2000   - loss = 1.649e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.558\n",
      "Epoch 1758   / 2000   - loss = 1.648e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.557\n",
      "Epoch 1759   / 2000   - loss = 1.648e+02 - val loss = 1.645e+02 -- est. noise std mean : 0.556\n",
      "Epoch 1760   / 2000   - loss = 1.652e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.556\n",
      "Epoch 1761   / 2000   - loss = 1.653e+02 - val loss = 1.647e+02 -- est. noise std mean : 0.555\n",
      "Epoch 1762   / 2000   - loss = 1.650e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.555\n",
      "Epoch 1763   / 2000   - loss = 1.652e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.555\n",
      "Epoch 1764   / 2000   - loss = 1.654e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.555\n",
      "Epoch 1765   / 2000   - loss = 1.649e+02 - val loss = 1.647e+02 -- est. noise std mean : 0.556\n",
      "Epoch 1766   / 2000   - loss = 1.645e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.555\n",
      "Epoch 1767   / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.555\n",
      "Epoch 1768   / 2000   - loss = 1.654e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.555\n",
      "Epoch 1769   / 2000   - loss = 1.652e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.555\n",
      "Epoch 1770   / 2000   - loss = 1.647e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.555\n",
      "Epoch 1771   / 2000   - loss = 1.650e+02 - val loss = 1.657e+02 -- est. noise std mean : 0.555\n",
      "Epoch 1772   / 2000   - loss = 1.655e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.556\n",
      "Epoch 1773   / 2000   - loss = 1.649e+02 - val loss = 1.647e+02 -- est. noise std mean : 0.556\n",
      "Epoch 1774   / 2000   - loss = 1.651e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.557\n",
      "Epoch 1775   / 2000   - loss = 1.650e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.557\n",
      "Epoch 1776   / 2000   - loss = 1.648e+02 - val loss = 1.646e+02 -- est. noise std mean : 0.557\n",
      "Epoch 1777   / 2000   - loss = 1.653e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.557\n",
      "Epoch 1778   / 2000   - loss = 1.653e+02 - val loss = 1.645e+02 -- est. noise std mean : 0.558\n",
      "Epoch 1779   / 2000   - loss = 1.652e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1780   / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1781   / 2000   - loss = 1.649e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1782   / 2000   - loss = 1.649e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1783   / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1784   / 2000   - loss = 1.649e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1785   / 2000   - loss = 1.650e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1786   / 2000   - loss = 1.652e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1787   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1788   / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1789   / 2000   - loss = 1.649e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1790   / 2000   - loss = 1.648e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1791   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1792   / 2000   - loss = 1.650e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1793   / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.558\n",
      "Epoch 1794   / 2000   - loss = 1.654e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1795   / 2000   - loss = 1.652e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1796   / 2000   - loss = 1.649e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1797   / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1798   / 2000   - loss = 1.652e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1799   / 2000   - loss = 1.651e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1800   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1801   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1802   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1803   / 2000   - loss = 1.650e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1804   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1805   / 2000   - loss = 1.650e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1806   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1807   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1808   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1809   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1810   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1811   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1812   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1813   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1814   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1815   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1816   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1817   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1818   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1819   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1820   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1821   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1822   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1823   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1824   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1825   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1826   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1827   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.572\n",
      "Epoch 1828   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.572\n",
      "Epoch 1829   / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.574\n",
      "Epoch 1830   / 2000   - loss = 1.649e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.575\n",
      "Epoch 1831   / 2000   - loss = 1.653e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.576\n",
      "Epoch 1832   / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.576\n",
      "Epoch 1833   / 2000   - loss = 1.650e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.577\n",
      "Epoch 1834   / 2000   - loss = 1.650e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.577\n",
      "Epoch 1835   / 2000   - loss = 1.649e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.577\n",
      "Epoch 1836   / 2000   - loss = 1.648e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.578\n",
      "Epoch 1837   / 2000   - loss = 1.658e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.578\n",
      "Epoch 1838   / 2000   - loss = 1.648e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.578\n",
      "Epoch 1839   / 2000   - loss = 1.652e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.578\n",
      "Epoch 1840   / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.577\n",
      "Epoch 1841   / 2000   - loss = 1.650e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.577\n",
      "Epoch 1842   / 2000   - loss = 1.650e+02 - val loss = 1.658e+02 -- est. noise std mean : 0.577\n",
      "Epoch 1843   / 2000   - loss = 1.654e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.576\n",
      "Epoch 1844   / 2000   - loss = 1.650e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.575\n",
      "Epoch 1845   / 2000   - loss = 1.653e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.574\n",
      "Epoch 1846   / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.574\n",
      "Epoch 1847   / 2000   - loss = 1.655e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.572\n",
      "Epoch 1848   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.571\n",
      "Epoch 1849   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1850   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1851   / 2000   - loss = 1.650e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1852   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1853   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1854   / 2000   - loss = 1.655e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1855   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1856   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1857   / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1858   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1859   / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1860   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1861   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1862   / 2000   - loss = 1.650e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1863   / 2000   - loss = 1.653e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1864   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1865   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1866   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1867   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1868   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1869   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1870   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1871   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1872   / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1873   / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1874   / 2000   - loss = 1.649e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1875   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1876   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1877   / 2000   - loss = 1.649e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1878   / 2000   - loss = 1.653e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1879   / 2000   - loss = 1.649e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1880   / 2000   - loss = 1.652e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1881   / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1882   / 2000   - loss = 1.649e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1883   / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1884   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1885   / 2000   - loss = 1.650e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1886   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1887   / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1888   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1889   / 2000   - loss = 1.650e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1890   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1891   / 2000   - loss = 1.650e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1892   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1893   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1894   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1895   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1896   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1897   / 2000   - loss = 1.650e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1898   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1899   / 2000   - loss = 1.649e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1900   / 2000   - loss = 1.649e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1901   / 2000   - loss = 1.649e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1902   / 2000   - loss = 1.649e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1903   / 2000   - loss = 1.656e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.558\n",
      "Epoch 1904   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.558\n",
      "Epoch 1905   / 2000   - loss = 1.648e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.558\n",
      "Epoch 1906   / 2000   - loss = 1.651e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.558\n",
      "Epoch 1907   / 2000   - loss = 1.652e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.558\n",
      "Epoch 1908   / 2000   - loss = 1.654e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.558\n",
      "Epoch 1909   / 2000   - loss = 1.650e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1910   / 2000   - loss = 1.648e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1911   / 2000   - loss = 1.651e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1912   / 2000   - loss = 1.650e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1913   / 2000   - loss = 1.648e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1914   / 2000   - loss = 1.648e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.558\n",
      "Epoch 1915   / 2000   - loss = 1.653e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.558\n",
      "Epoch 1916   / 2000   - loss = 1.649e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.558\n",
      "Epoch 1917   / 2000   - loss = 1.649e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.558\n",
      "Epoch 1918   / 2000   - loss = 1.650e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.557\n",
      "Epoch 1919   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.557\n",
      "Epoch 1920   / 2000   - loss = 1.650e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.557\n",
      "Epoch 1921   / 2000   - loss = 1.652e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.557\n",
      "Epoch 1922   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.558\n",
      "Epoch 1923   / 2000   - loss = 1.650e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.558\n",
      "Epoch 1924   / 2000   - loss = 1.650e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.558\n",
      "Epoch 1925   / 2000   - loss = 1.654e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1926   / 2000   - loss = 1.649e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1927   / 2000   - loss = 1.649e+02 - val loss = 1.656e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1928   / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1929   / 2000   - loss = 1.649e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1930   / 2000   - loss = 1.649e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1931   / 2000   - loss = 1.652e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1932   / 2000   - loss = 1.651e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1933   / 2000   - loss = 1.650e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1934   / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1935   / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1936   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1937   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1938   / 2000   - loss = 1.655e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1939   / 2000   - loss = 1.650e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1940   / 2000   - loss = 1.649e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1941   / 2000   - loss = 1.650e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.563\n",
      "Epoch 1942   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1943   / 2000   - loss = 1.650e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1944   / 2000   - loss = 1.649e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1945   / 2000   - loss = 1.653e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.558\n",
      "Epoch 1946   / 2000   - loss = 1.648e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.557\n",
      "Epoch 1947   / 2000   - loss = 1.650e+02 - val loss = 1.654e+02 -- est. noise std mean : 0.557\n",
      "Epoch 1948   / 2000   - loss = 1.649e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.556\n",
      "Epoch 1949   / 2000   - loss = 1.650e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.555\n",
      "Epoch 1950   / 2000   - loss = 1.657e+02 - val loss = 1.655e+02 -- est. noise std mean : 0.555\n",
      "Epoch 1951   / 2000   - loss = 1.655e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.556\n",
      "Epoch 1952   / 2000   - loss = 1.652e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.556\n",
      "Epoch 1953   / 2000   - loss = 1.649e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.557\n",
      "Epoch 1954   / 2000   - loss = 1.652e+02 - val loss = 1.648e+02 -- est. noise std mean : 0.558\n",
      "Epoch 1955   / 2000   - loss = 1.649e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.558\n",
      "Epoch 1956   / 2000   - loss = 1.649e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1957   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.559\n",
      "Epoch 1958   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.560\n",
      "Epoch 1959   / 2000   - loss = 1.650e+02 - val loss = 1.649e+02 -- est. noise std mean : 0.561\n",
      "Epoch 1960   / 2000   - loss = 1.656e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.562\n",
      "Epoch 1961   / 2000   - loss = 1.651e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.564\n",
      "Epoch 1962   / 2000   - loss = 1.650e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1963   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.565\n",
      "Epoch 1964   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1965   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1966   / 2000   - loss = 1.653e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1967   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1968   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1969   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1970   / 2000   - loss = 1.650e+02 - val loss = 1.653e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1971   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1972   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1973   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1974   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1975   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1976   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1977   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1978   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1979   / 2000   - loss = 1.653e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.566\n",
      "Epoch 1980   / 2000   - loss = 1.652e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1981   / 2000   - loss = 1.651e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1982   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1983   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1984   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1985   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1986   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.567\n",
      "Epoch 1987   / 2000   - loss = 1.650e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.568\n",
      "Epoch 1988   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1989   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1990   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1991   / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1992   / 2000   - loss = 1.652e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1993   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1994   / 2000   - loss = 1.651e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1995   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1996   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.569\n",
      "Epoch 1997   / 2000   - loss = 1.650e+02 - val loss = 1.652e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1998   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.570\n",
      "Epoch 1999   / 2000   - loss = 1.650e+02 - val loss = 1.650e+02 -- est. noise std mean : 0.571\n",
      "Epoch 2000   / 2000   - loss = 1.650e+02 - val loss = 1.651e+02 -- est. noise std mean : 0.573\n"
     ]
    }
   ],
   "source": [
    "# Clear old parameters\n",
    "pyro.clear_param_store()\n",
    "# debug\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# training parameters\n",
    "n_epochs = 2000\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "for step in range(n_epochs):\n",
    "    # perform the training : compute and backprop gradients\n",
    "    loss = svi.step(X,y)\n",
    "    # perform evaluation only\n",
    "    with torch.no_grad():\n",
    "        eval_loss = svi.evaluate_loss(X,y)\n",
    "    # log the results\n",
    "    training_losses.append(loss)\n",
    "    validation_losses.append(eval_loss)\n",
    "    # get the parameters\n",
    "    est_log_noise_std_loc = pyro.param(\"log_noise_std_loc\")\n",
    "    est_log_noise_std_std = pyro.param(\"log_noise_std_scale\")\n",
    "    est_noise_std_loc = torch.exp(est_log_noise_std_loc)\n",
    "    # report out\n",
    "    print(f'Epoch {step+1:<6} / {n_epochs:<6} - loss = {loss:.3e} - val loss = {eval_loss:.3e} -- est. noise std mean : {est_noise_std_loc.item():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b33b0f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "\n",
    "ax.plot(training_losses, label='training')\n",
    "ax.plot(validation_losses, label='validation')\n",
    "ax.set_title(f'Losses in MLE run')\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef150478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth = 0.100, learned noise = 0.573\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ground truth = {noise.item():.3f}, learned noise = {est_noise_std_loc.item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffafac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished sampling 1000 predictive vectors.\n"
     ]
    }
   ],
   "source": [
    "# here, we want to draw samples from the trained model on known X's\n",
    "import pyro.poutine as poutine\n",
    "\n",
    "N_SAMPLES = 1000\n",
    "N_POINTS = X.shape[0]\n",
    "\n",
    "# place holder for predictions.\n",
    "# at each point, draw samples of the predicted value.\n",
    "y_preds = torch.zeros((N_POINTS, N_SAMPLES)).to(device)\n",
    "\n",
    "for s in range(N_SAMPLES):\n",
    "    # STEP 1: Trace the execution of the prediction guide.\n",
    "    # The trace records the *value* of the sampled parameters (a, b, log_noise_std).\n",
    "    # posterior_trace = poutine.trace(posterior_sampler).get_trace(X)\n",
    "    # NB : here we used the q_phi guide/approximate posterior, and \n",
    "    #       did not write a specific simpler posterior sampler\n",
    "    posterior_trace = poutine.trace(q_phi).get_trace(X)\n",
    "    \n",
    "    # STEP 2: Use the Replay Poutine on the Model.\n",
    "    # This forces the Model to use the parameter values recorded in guide_trace.\n",
    "    with poutine.replay(trace=posterior_trace):\n",
    "        # STEP 3: Execute the Model to draw a prediction.\n",
    "        # Calling model(X) with y=None tells the 'obs' site to draw a sample \n",
    "        # (the predicted y) using the replayed (fixed) parameters.\n",
    "        predicted_y_vector = model(X, y=None) \n",
    "    \n",
    "    # STEP 4: Store the resulting vector of predictions for all N_POINTS\n",
    "    y_preds[:, s] = predicted_y_vector.squeeze()\n",
    "\n",
    "print(f\"Finished sampling {N_SAMPLES} predictive vectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2747b165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "\n",
    "ax.scatter(X.detach().cpu(),y.detach().cpu(), marker='x', label='ground truth')\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "ax.set_title(f'posterior predictions with SVI')\n",
    "for s in range(N_SAMPLES):\n",
    "    ax.scatter(X.cpu(), y_preds[:,s].detach().cpu(), alpha=0.05, color='green', marker='.')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
